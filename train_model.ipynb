{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa73b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_optimized.py\n",
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import torch # type: ignore\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "from torch.utils.data import Dataset, DataLoader # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix # type: ignore\n",
    "from tqdm import tqdm # type: ignore\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 40\n",
    "LR = 1e-3\n",
    "VAL_SPLIT = 0.2\n",
    "PATIENCE = 7               # early stopping patience (on val F1)\n",
    "PER_ELEC_CHANNELS = 8\n",
    "SPATIAL_OUT = 32\n",
    "LSTM_HIDDEN = 64\n",
    "DROPOUT = 0.3\n",
    "GRAD_CLIP = 1.0            # gradient clipping\n",
    "NUM_WORKERS = 0            # Windows: keep 0; change if on Linux and you want speed\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# ---------------- Dataset (lazy per-file load) ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item is one .npy file shaped (segments=44, time_windows=8, H=5, W=5, features=200)\n",
    "    Label 0=healthy,1=patient\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, folders=(\"healthy\",\"patient\")):\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        # deterministic order\n",
    "        idxs = np.argsort(self.files)\n",
    "        self.files = [self.files[i] for i in idxs]\n",
    "        self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.files[idx])   # expected (44,8,5,5,200)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[idx]} shape {arr.shape} != (44,8,5,5,200)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        # per-file normalization (global)\n",
    "        arr = (arr - arr.mean()) / (arr.std() + 1e-6)\n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class FullEEGModel(nn.Module):\n",
    "    def __init__(self, per_elec_channels=PER_ELEC_CHANNELS, spatial_out=SPATIAL_OUT,\n",
    "                 lstm_hidden=LSTM_HIDDEN, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        # per-electrode temporal conv\n",
    "        self.temporal_conv = nn.Sequential(\n",
    "            nn.Conv1d(1, per_elec_channels, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(per_elec_channels, per_elec_channels, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        # per-segment spatial conv (C, H, W) -> spatial_out\n",
    "        self.spatial_conv = nn.Sequential(\n",
    "            nn.Conv2d(per_elec_channels, per_elec_channels*2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(per_elec_channels*2, spatial_out, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        # global spatial branch\n",
    "        self.global_spatial_conv = nn.Sequential(\n",
    "            nn.Conv2d(per_elec_channels, per_elec_channels*2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        # LSTM over segments (44)\n",
    "        self.lstm = nn.LSTM(input_size=spatial_out, hidden_size=lstm_hidden, batch_first=True)\n",
    "        # classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden + (per_elec_channels*2), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, S=44, T=8, H=5, W=5, F=200)\n",
    "        B, S, T, H, W, F = x.shape\n",
    "        # apply 1D conv per electrode: reshape to (B*S*T*H*W, 1, F)\n",
    "        x_flat = x.view(B*S*T*H*W, F).unsqueeze(1)\n",
    "        tc = self.temporal_conv(x_flat).squeeze(-1)   # (N, per_elec_channels)\n",
    "        C = tc.shape[1]\n",
    "        tc = tc.view(B, S, T, C, H, W)                # (B, S, T, C, H, W)\n",
    "        # collapse T (intra-segment windows) by mean -> (B, S, C, H, W)\n",
    "        per_segment_map = tc.mean(dim=2)\n",
    "        # spatial conv per-segment\n",
    "        segs = per_segment_map.view(B*S, C, H, W)\n",
    "        sp = self.spatial_conv(segs).view(B, S, -1)   # (B, S, spatial_out)\n",
    "        # LSTM across segments\n",
    "        lstm_out, _ = self.lstm(sp)                   # (B, S, lstm_hidden)\n",
    "        lstm_last = lstm_out[:, -1, :]\n",
    "        # global spatial map (avg across segments) -> conv\n",
    "        global_map = per_segment_map.mean(dim=1)      # (B, C, H, W)\n",
    "        gsp = self.global_spatial_conv(global_map).view(B, -1)  # (B, C2)\n",
    "        # concat and classify\n",
    "        cat = torch.cat([lstm_last, gsp], dim=1)\n",
    "        logits = self.classifier(cat).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def prepare_loaders(data_dir, batch_size=BATCH_SIZE, val_split=VAL_SPLIT, seed=SEED):\n",
    "    ds = EEGFileDataset(data_dir)\n",
    "    indices = np.arange(len(ds))\n",
    "    labels = np.array([ds[i][1].item() for i in range(len(ds))])\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=val_split, stratify=labels, random_state=seed)\n",
    "    train_ds = torch.utils.data.Subset(ds, train_idx)\n",
    "    val_ds = torch.utils.data.Subset(ds, val_idx)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    # compute pos_weight using training labels only\n",
    "    train_labels = labels[train_idx]\n",
    "    neg = (train_labels == 0).sum()\n",
    "    pos = (train_labels == 1).sum()\n",
    "    pos_weight = torch.tensor([neg / (pos + 1e-12)], dtype=torch.float32).to(DEVICE)\n",
    "    print(f\"Files total={len(ds)} train={len(train_ds)} val={len(val_ds)} | train healthy={neg} patient={pos} pos_weight={pos_weight.item():.3f}\")\n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Train & Eval ----------------\n",
    "def train_and_evaluate():\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders(DATA_DIR)\n",
    "    model = FullEEGModel().to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    best_val_f1 = 0.0\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} - train\"):\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE).float()\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} - val\"):\n",
    "                Xv = Xv.to(DEVICE)\n",
    "                yv = yv.to(DEVICE).float()\n",
    "                logits = model(Xv)\n",
    "                loss = criterion(logits, yv)\n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "                trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        avg_train = float(np.mean(train_losses)) if train_losses else 0.0\n",
    "        avg_val = float(np.mean(val_losses)) if val_losses else 0.0\n",
    "        acc = accuracy_score(trues, preds) if len(trues)>0 else 0.0\n",
    "        prec = precision_score(trues, preds, zero_division=0)\n",
    "        rec = recall_score(trues, preds, zero_division=0)\n",
    "        f1 = f1_score(trues, preds, zero_division=0)\n",
    "        print(f\"[{epoch}/{EPOCHS}] TrainLoss={avg_train:.4f} ValLoss={avg_val:.4f} | Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} F1={f1:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_val)\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(f\"Current Learning Rate: {param_group['lr']:.6f}\")\n",
    "\n",
    "        # early stopping on val F1\n",
    "        if f1 > best_val_f1 + 1e-4:\n",
    "            best_val_f1 = f1\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(f\"  Saved best model (val F1={best_val_f1:.4f})\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # final evaluation\n",
    "    if os.path.exists(\"best_model.pth\"):\n",
    "        model.load_state_dict(torch.load(\"best_model.pth\", map_location=DEVICE))\n",
    "        print(\"\\nLoaded best_model.pth for final evaluation.\")\n",
    "    else:\n",
    "        print(\"\\nNo saved best model; evaluating last model state.\")\n",
    "\n",
    "    all_preds, all_trues = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in tqdm(val_loader, desc=\"Final evaluation\"):\n",
    "            Xv = Xv.to(DEVICE)\n",
    "            yv = yv.to(DEVICE)\n",
    "            logits = model(Xv)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    prec = precision_score(all_trues, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_trues, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "\n",
    "    print(\"\\n=== FINAL VALIDATION RESULTS ===\")\n",
    "    print(f\"Samples (val): {len(all_trues)}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "    print(cm)\n",
    "    print(\"\\nBest model saved to best_model.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033cc946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_optimized.py\n",
    "\n",
    "import os\n",
    "import numpy as np  # type: ignore\n",
    "import torch  # type: ignore\n",
    "import torch.nn as nn  # type: ignore\n",
    "import torch.optim as optim  # type: ignore\n",
    "from torch.utils.data import Dataset, DataLoader  # type: ignore\n",
    "from sklearn.model_selection import train_test_split  # type: ignore\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix  # type: ignore\n",
    "from tqdm import tqdm  # type: ignore\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 40\n",
    "LR = 2e-3\n",
    "VAL_SPLIT = 0.2\n",
    "PATIENCE = 15               # early stopping patience (on val F1)\n",
    "PER_ELEC_CHANNELS = 8\n",
    "SPATIAL_OUT = 32\n",
    "LSTM_HIDDEN = 64\n",
    "DROPOUT = 0.3\n",
    "GRAD_CLIP = 1.0             # gradient clipping\n",
    "NUM_WORKERS = 0             # Windows: keep 0; change if on Linux and you want speed\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# ---------------- Dataset (lazy per-file load) ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item is one .npy file shaped (segments=44, time_windows=8, H=5, W=5, features=200)\n",
    "    Label 0=healthy,1=patient\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, folders=(\"healthy\", \"patient\")):\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        # deterministic order\n",
    "        idxs = np.argsort(self.files)\n",
    "        self.files = [self.files[i] for i in idxs]\n",
    "        self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.files[idx])  # expected (44,8,5,5,200)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[idx]} shape {arr.shape} != (44,8,5,5,200)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        # Improved normalization: feature-wise instead of global per file\n",
    "        arr = (arr - np.mean(arr, axis=(0, 1, 2, 3), keepdims=True)) / (\n",
    "            np.std(arr, axis=(0, 1, 2, 3), keepdims=True) + 1e-6\n",
    "        )\n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class FullEEGModel(nn.Module):\n",
    "    def __init__(self, per_elec_channels=PER_ELEC_CHANNELS, spatial_out=SPATIAL_OUT,\n",
    "                 lstm_hidden=LSTM_HIDDEN, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        # per-electrode temporal conv\n",
    "        self.temporal_conv = nn.Sequential(\n",
    "            nn.Conv1d(1, per_elec_channels, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(per_elec_channels, per_elec_channels, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        # per-segment spatial conv (C, H, W) -> spatial_out\n",
    "        self.spatial_conv = nn.Sequential(\n",
    "            nn.Conv2d(per_elec_channels, per_elec_channels*2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(per_elec_channels*2, spatial_out, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        # global spatial branch\n",
    "        self.global_spatial_conv = nn.Sequential(\n",
    "            nn.Conv2d(per_elec_channels, per_elec_channels*2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        # LSTM over segments (44)\n",
    "        self.lstm = nn.LSTM(input_size=spatial_out, hidden_size=lstm_hidden, batch_first=True)\n",
    "        # classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden + (per_elec_channels*2), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, S=44, T=8, H=5, W=5, F=200)\n",
    "        B, S, T, H, W, F = x.shape\n",
    "        # apply 1D conv per electrode: reshape to (B*S*T*H*W, 1, F)\n",
    "        x_flat = x.view(B*S*T*H*W, F).unsqueeze(1)\n",
    "        tc = self.temporal_conv(x_flat).squeeze(-1)   # (N, per_elec_channels)\n",
    "        C = tc.shape[1]\n",
    "        tc = tc.view(B, S, T, C, H, W)                # (B, S, T, C, H, W)\n",
    "        # collapse T (intra-segment windows) by mean -> (B, S, C, H, W)\n",
    "        per_segment_map = tc.mean(dim=2)\n",
    "        # spatial conv per-segment\n",
    "        segs = per_segment_map.view(B*S, C, H, W)\n",
    "        sp = self.spatial_conv(segs).view(B, S, -1)   # (B, S, spatial_out)\n",
    "        # LSTM across segments\n",
    "        lstm_out, _ = self.lstm(sp)                   # (B, S, lstm_hidden)\n",
    "        lstm_last = lstm_out[:, -1, :]\n",
    "        # global spatial map (avg across segments) -> conv\n",
    "        global_map = per_segment_map.mean(dim=1)      # (B, C, H, W)\n",
    "        gsp = self.global_spatial_conv(global_map).view(B, -1)  # (B, C2)\n",
    "        # concat and classify\n",
    "        cat = torch.cat([lstm_last, gsp], dim=1)\n",
    "        logits = self.classifier(cat).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def prepare_loaders(data_dir, batch_size=BATCH_SIZE, val_split=VAL_SPLIT, seed=SEED):\n",
    "    ds = EEGFileDataset(data_dir)\n",
    "    indices = np.arange(len(ds))\n",
    "    labels = np.array([ds[i][1].item() for i in range(len(ds))])\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=val_split, stratify=labels, random_state=seed)\n",
    "    train_ds = torch.utils.data.Subset(ds, train_idx)\n",
    "    val_ds = torch.utils.data.Subset(ds, val_idx)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    # compute pos_weight using corrected formula\n",
    "    train_labels = labels[train_idx]\n",
    "    neg = (train_labels == 0).sum()\n",
    "    pos = (train_labels == 1).sum()\n",
    "    pos_weight = torch.tensor([pos / (neg + 1e-12)], dtype=torch.float32).to(DEVICE)\n",
    "    print(f\"Files total={len(ds)} train={len(train_ds)} val={len(val_ds)} | train healthy={neg} patient={pos} pos_weight={pos_weight.item():.3f}\")\n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Train & Eval ----------------\n",
    "def train_and_evaluate():\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders(DATA_DIR)\n",
    "    model = FullEEGModel().to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "    best_val_f1 = 0.0\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} - train\"):\n",
    "            X_batch = X_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE).float()\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} - val\"):\n",
    "                Xv = Xv.to(DEVICE)\n",
    "                yv = yv.to(DEVICE).float()\n",
    "                logits = model(Xv)\n",
    "                loss = criterion(logits, yv)\n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "                trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        avg_train = float(np.mean(train_losses)) if train_losses else 0.0\n",
    "        avg_val = float(np.mean(val_losses)) if val_losses else 0.0\n",
    "        acc = accuracy_score(trues, preds) if len(trues) > 0 else 0.0\n",
    "        prec = precision_score(trues, preds, zero_division=0)\n",
    "        rec = recall_score(trues, preds, zero_division=0)\n",
    "        f1 = f1_score(trues, preds, zero_division=0)\n",
    "        print(f\"[{epoch}/{EPOCHS}] TrainLoss={avg_train:.4f} ValLoss={avg_val:.4f} | Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} F1={f1:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_val)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(f\"Current Learning Rate: {param_group['lr']:.6f}\")\n",
    "\n",
    "        # early stopping on val F1\n",
    "        if f1 > best_val_f1 + 1e-4:\n",
    "            best_val_f1 = f1\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(f\"  Saved best model (val F1={best_val_f1:.4f})\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # final evaluation\n",
    "    if os.path.exists(\"best_model.pth\"):\n",
    "        model.load_state_dict(torch.load(\"best_model.pth\", map_location=DEVICE))\n",
    "        print(\"\\nLoaded best_model.pth for final evaluation.\")\n",
    "    else:\n",
    "        print(\"\\nNo saved best model; evaluating last model state.\")\n",
    "\n",
    "    all_preds, all_trues = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in tqdm(val_loader, desc=\"Final evaluation\"):\n",
    "            Xv = Xv.to(DEVICE)\n",
    "            yv = yv.to(DEVICE)\n",
    "            logits = model(Xv)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    prec = precision_score(all_trues, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_trues, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "\n",
    "    print(\"\\n=== FINAL VALIDATION RESULTS ===\")\n",
    "    print(f\"Samples (val): {len(all_trues)}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "    print(cm)\n",
    "    print(\"\\nBest model saved to best_model.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 8  # Increased for better gradient estimates\n",
    "EPOCHS = 60\n",
    "LR = 5e-4  # Increased learning rate\n",
    "VAL_SPLIT = 0.2\n",
    "PATIENCE = 10\n",
    "LSTM_HIDDEN = 64  # Increased capacity\n",
    "LSTM_LAYERS = 2  # Added depth\n",
    "DROPOUT = 0.4\n",
    "GRAD_CLIP = 1.0\n",
    "NUM_WORKERS = 0\n",
    "AUGMENT = True\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    def __init__(self, data_dir, folders=(\"healthy\",\"patient\"), augment=False):\n",
    "        self.augment = augment\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        idxs = np.argsort(self.files)\n",
    "        self.files = [self.files[i] for i in idxs]\n",
    "        self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.files[idx])  # shape (44,8,5,5,200)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[idx]} shape {arr.shape} != (44,8,5,5,200)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        \n",
    "        # Better feature extraction: flatten spatial but keep channels\n",
    "        # (44,8,5,5,200) -> (44, 8*5*5, 200) -> (44, 200, 200) after reshaping\n",
    "        T, C, H, W, F = arr.shape\n",
    "        # Reshape to (44, 200, 200) - treating channel*spatial as features\n",
    "        arr = arr.reshape(T, C*H*W, F)  # (44, 200, 200)\n",
    "        \n",
    "        # Normalize per channel across time\n",
    "        mean = arr.mean(axis=(0, 2), keepdims=True)\n",
    "        std = arr.std(axis=(0, 2), keepdims=True) + 1e-6\n",
    "        arr = (arr - mean) / std\n",
    "        \n",
    "        # Average across the channel dimension for manageable size\n",
    "        arr = arr.mean(axis=1)  # (44, 200)\n",
    "        \n",
    "        # Augmentation only during training\n",
    "        if self.augment:\n",
    "            # Gaussian noise\n",
    "            arr += np.random.normal(0, 0.02, arr.shape).astype(np.float32)\n",
    "            # Random amplitude scaling\n",
    "            scale = np.random.uniform(0.95, 1.05)\n",
    "            arr *= scale\n",
    "        \n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class ImprovedLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=200, hidden_size=LSTM_HIDDEN, num_layers=LSTM_LAYERS, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True  # Use bidirectional for better context\n",
    "        )\n",
    "        \n",
    "        # Classifier with batch norm\n",
    "        lstm_output_size = hidden_size * 2  # *2 for bidirectional\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif 'weight' in name and param.dim() >= 2:\n",
    "                nn.init.kaiming_normal_(param.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 44, 200)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Use last output\n",
    "        last = lstm_out[:, -1, :]\n",
    "        logits = self.classifier(last).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def prepare_loaders(data_dir):\n",
    "    # Create datasets with augmentation flag\n",
    "    full_ds = EEGFileDataset(data_dir, augment=False)\n",
    "    indices = np.arange(len(full_ds))\n",
    "    labels = np.array([full_ds[i][1].item() for i in range(len(full_ds))])\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=VAL_SPLIT, stratify=labels, random_state=SEED\n",
    "    )\n",
    "    \n",
    "    # Create separate datasets for train (with augment) and val (without)\n",
    "    train_ds_aug = EEGFileDataset(data_dir, augment=True)\n",
    "    train_ds = torch.utils.data.Subset(train_ds_aug, train_idx)\n",
    "    val_ds = torch.utils.data.Subset(full_ds, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "        num_workers=NUM_WORKERS, drop_last=True  # Drop last for batch norm\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    # Calculate class weights properly\n",
    "    train_labels = labels[train_idx]\n",
    "    neg = (train_labels == 0).sum()  # healthy\n",
    "    pos = (train_labels == 1).sum()  # patient\n",
    "    \n",
    "    # For BCEWithLogitsLoss, pos_weight should be neg/pos\n",
    "    pos_weight = torch.tensor([neg / (pos + 1e-12)], dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Dataset Info ===\")\n",
    "    print(f\"Total files: {len(full_ds)}\")\n",
    "    print(f\"Train: {len(train_ds)} (Healthy={neg}, Patient={pos})\")\n",
    "    print(f\"Val: {len(val_ds)}\")\n",
    "    print(f\"Pos_weight: {pos_weight.item():.3f}\")\n",
    "    print(f\"Class distribution in train: {neg/(neg+pos)*100:.1f}% healthy, {pos/(neg+pos)*100:.1f}% patient\\n\")\n",
    "    \n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Train & Eval ----------------\n",
    "def train_and_evaluate():\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders(DATA_DIR)\n",
    "    model = ImprovedLSTMModel().to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Model Info ===\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\\n\")\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=4\n",
    "    )\n",
    "\n",
    "    best_val_f1 = 0.0\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_trues = [], []\n",
    "        \n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} - train\"):\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            train_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            train_trues.extend(y.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_trues = [], []\n",
    "        val_probs_all = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in val_loader:\n",
    "                Xv = Xv.to(DEVICE)\n",
    "                yv = yv.to(DEVICE).float()\n",
    "                logits = model(Xv)\n",
    "                loss = criterion(logits, yv)\n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                val_probs_all.extend(probs.tolist())\n",
    "                val_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "                val_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        # Metrics\n",
    "        avg_train = float(np.mean(train_losses))\n",
    "        avg_val = float(np.mean(val_losses))\n",
    "        \n",
    "        train_acc = accuracy_score(train_trues, train_preds)\n",
    "        train_f1 = f1_score(train_trues, train_preds, zero_division=0)\n",
    "        \n",
    "        val_acc = accuracy_score(val_trues, val_preds)\n",
    "        val_prec = precision_score(val_trues, val_preds, zero_division=0)\n",
    "        val_rec = recall_score(val_trues, val_preds, zero_division=0)\n",
    "        val_f1 = f1_score(val_trues, val_preds, zero_division=0)\n",
    "        \n",
    "        # Check prediction distribution\n",
    "        unique_preds = np.unique(val_preds)\n",
    "        pred_dist = {int(p): val_preds.count(p) for p in unique_preds}\n",
    "        \n",
    "        print(f\"\\n[Epoch {epoch}/{EPOCHS}]\")\n",
    "        print(f\"  Train: Loss={avg_train:.4f}, Acc={train_acc:.4f}, F1={train_f1:.4f}\")\n",
    "        print(f\"  Val:   Loss={avg_val:.4f}, Acc={val_acc:.4f}, Prec={val_prec:.4f}, Rec={val_rec:.4f}, F1={val_f1:.4f}\")\n",
    "        print(f\"  Val predictions dist: {pred_dist}\")\n",
    "        print(f\"  Val prob range: [{min(val_probs_all):.3f}, {max(val_probs_all):.3f}]\")\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        scheduler.step(val_f1)\n",
    "\n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1 + 1e-4:\n",
    "            best_val_f1 = val_f1\n",
    "            no_improve = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_f1': val_f1,\n",
    "            }, \"best_model.pth\")\n",
    "            print(f\"  âœ“ Saved best model (val F1={best_val_f1:.4f})\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= PATIENCE:\n",
    "                print(f\"\\nEarly stopping triggered (no improvement for {PATIENCE} epochs)\")\n",
    "                break\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LOADING BEST MODEL FOR FINAL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if os.path.exists(\"best_model.pth\"):\n",
    "        checkpoint = torch.load(\"best_model.pth\", map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "    all_preds, all_trues, all_probs = [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            Xv = Xv.to(DEVICE)\n",
    "            yv = yv.to(DEVICE)\n",
    "            logits = model(Xv)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    prec = precision_score(all_trues, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_trues, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "\n",
    "    print(\"\\n=== FINAL VALIDATION RESULTS ===\")\n",
    "    print(f\"Validation samples: {len(all_trues)}\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"\\nPrediction distribution: {dict(zip(*np.unique(all_preds, return_counts=True)))}\")\n",
    "    print(f\"True label distribution: {dict(zip(*np.unique(all_trues, return_counts=True)))}\")\n",
    "    print(f\"Probability range: [{min(all_probs):.3f}, {max(all_probs):.3f}]\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(\"              Predicted\")\n",
    "    print(\"              0(H)  1(P)\")\n",
    "    print(f\"Actual  0(H)  {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "    print(f\"        1(P)  {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "    print(\"\\nModel saved to best_model.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "LR = 5e-4\n",
    "VAL_SPLIT = 0.2\n",
    "PATIENCE = 15  # More patience\n",
    "LSTM_HIDDEN = 64\n",
    "LSTM_LAYERS = 2\n",
    "DROPOUT = 0.45  # Slightly increased\n",
    "GRAD_CLIP = 1.0\n",
    "NUM_WORKERS = 0\n",
    "AUGMENT = True\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ---------------- Enhanced Dataset ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    def __init__(self, data_dir, folders=(\"healthy\",\"patient\"), augment=False):\n",
    "        self.augment = augment\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        idxs = np.argsort(self.files)\n",
    "        self.files = [self.files[i] for i in idxs]\n",
    "        self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.files[idx])  # shape (44,8,5,5,200)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[idx]} shape {arr.shape} != (44,8,5,5,200)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        \n",
    "        T, C, H, W, F = arr.shape\n",
    "        arr = arr.reshape(T, C*H*W, F)\n",
    "        \n",
    "        # Normalize per channel across time\n",
    "        mean = arr.mean(axis=(0, 2), keepdims=True)\n",
    "        std = arr.std(axis=(0, 2), keepdims=True) + 1e-6\n",
    "        arr = (arr - mean) / std\n",
    "        \n",
    "        # Average across the channel dimension\n",
    "        arr = arr.mean(axis=1)  # (44, 200)\n",
    "        \n",
    "        # Enhanced augmentation\n",
    "        if self.augment:\n",
    "            # 1. Gaussian noise with varying intensity\n",
    "            noise_std = np.random.uniform(0.015, 0.04)\n",
    "            arr += np.random.normal(0, noise_std, arr.shape).astype(np.float32)\n",
    "            \n",
    "            # 2. Amplitude scaling\n",
    "            scale = np.random.uniform(0.92, 1.08)\n",
    "            arr *= scale\n",
    "            \n",
    "            # 3. Time shift (50% probability)\n",
    "            if np.random.rand() > 0.5:\n",
    "                shift = np.random.randint(-3, 4)\n",
    "                arr = np.roll(arr, shift, axis=0)\n",
    "        \n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- Improved Model ----------------\n",
    "class ImprovedLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=200, hidden_size=LSTM_HIDDEN, num_layers=LSTM_LAYERS, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        lstm_output_size = hidden_size * 2\n",
    "        \n",
    "        # Simple attention: learn importance of each time step\n",
    "        self.attention_weights = nn.Linear(lstm_output_size, 1)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif 'weight' in name and param.dim() >= 2:\n",
    "                nn.init.kaiming_normal_(param.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 44, 200)\n",
    "        lstm_out, _ = self.lstm(x)  # (B, 44, hidden*2)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attn_scores = self.attention_weights(lstm_out)  # (B, 44, 1)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        \n",
    "        # Weighted sum of all time steps\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)  # (B, hidden*2)\n",
    "        \n",
    "        logits = self.classifier(context).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Label Smoothing Loss ----------------\n",
    "class LabelSmoothingBCELoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.pos_weight = pos_weight\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        # Apply label smoothing: 0 -> 0.1, 1 -> 0.9\n",
    "        targets = targets * (1 - self.smoothing) + self.smoothing / 2\n",
    "        return nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=self.pos_weight\n",
    "        )\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def prepare_loaders(data_dir):\n",
    "    full_ds = EEGFileDataset(data_dir, augment=False)\n",
    "    indices = np.arange(len(full_ds))\n",
    "    labels = np.array([full_ds[i][1].item() for i in range(len(full_ds))])\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=VAL_SPLIT, stratify=labels, random_state=SEED\n",
    "    )\n",
    "    \n",
    "    train_ds_aug = EEGFileDataset(data_dir, augment=True)\n",
    "    train_ds = torch.utils.data.Subset(train_ds_aug, train_idx)\n",
    "    val_ds = torch.utils.data.Subset(full_ds, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "        num_workers=NUM_WORKERS, drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    train_labels = labels[train_idx]\n",
    "    neg = (train_labels == 0).sum()\n",
    "    pos = (train_labels == 1).sum()\n",
    "    pos_weight = torch.tensor([neg / (pos + 1e-12)], dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Dataset Info ===\")\n",
    "    print(f\"Total files: {len(full_ds)}\")\n",
    "    print(f\"Train: {len(train_ds)} (Healthy={neg}, Patient={pos})\")\n",
    "    print(f\"Val: {len(val_ds)}\")\n",
    "    print(f\"Pos_weight: {pos_weight.item():.3f}\")\n",
    "    print(f\"Class distribution in train: {neg/(neg+pos)*100:.1f}% healthy, {pos/(neg+pos)*100:.1f}% patient\\n\")\n",
    "    \n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Train & Eval ----------------\n",
    "def train_and_evaluate():\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders(DATA_DIR)\n",
    "    model = ImprovedLSTMModel().to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Model Info ===\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\\n\")\n",
    "    \n",
    "    # Use label smoothing for better generalization\n",
    "    criterion = LabelSmoothingBCELoss(smoothing=0.1, pos_weight=pos_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "    \n",
    "    # Cosine annealing with warm restarts for better convergence\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "\n",
    "    best_val_f1 = 0.0\n",
    "    best_val_acc = 0.0\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_trues = [], []\n",
    "        \n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} - train\", leave=False):\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            train_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            train_trues.extend(y.cpu().numpy().astype(int).tolist())\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_trues = [], []\n",
    "        val_probs_all = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in val_loader:\n",
    "                Xv = Xv.to(DEVICE)\n",
    "                yv = yv.to(DEVICE).float()\n",
    "                logits = model(Xv)\n",
    "                loss = criterion(logits, yv)\n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                val_probs_all.extend(probs.tolist())\n",
    "                val_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "                val_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        # Metrics\n",
    "        avg_train = float(np.mean(train_losses))\n",
    "        avg_val = float(np.mean(val_losses))\n",
    "        \n",
    "        train_acc = accuracy_score(train_trues, train_preds)\n",
    "        train_f1 = f1_score(train_trues, train_preds, zero_division=0)\n",
    "        \n",
    "        val_acc = accuracy_score(val_trues, val_preds)\n",
    "        val_prec = precision_score(val_trues, val_preds, zero_division=0)\n",
    "        val_rec = recall_score(val_trues, val_preds, zero_division=0)\n",
    "        val_f1 = f1_score(val_trues, val_preds, zero_division=0)\n",
    "        \n",
    "        # Check prediction distribution\n",
    "        unique_preds = np.unique(val_preds)\n",
    "        pred_dist = {int(p): val_preds.count(p) for p in unique_preds}\n",
    "        \n",
    "        print(f\"\\n[Epoch {epoch}/{EPOCHS}]\")\n",
    "        print(f\"  Train: Loss={avg_train:.4f}, Acc={train_acc:.4f}, F1={train_f1:.4f}\")\n",
    "        print(f\"  Val:   Loss={avg_val:.4f}, Acc={val_acc:.4f}, Prec={val_prec:.4f}, Rec={val_rec:.4f}, F1={val_f1:.4f}\")\n",
    "        print(f\"  Val predictions dist: {pred_dist}\")\n",
    "        print(f\"  Val prob range: [{min(val_probs_all):.3f}, {max(val_probs_all):.3f}]\")\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        # Save best model (prioritize F1, then accuracy)\n",
    "        is_better = (val_f1 > best_val_f1 + 1e-4) or \\\n",
    "                    (abs(val_f1 - best_val_f1) < 1e-4 and val_acc > best_val_acc)\n",
    "        \n",
    "        if is_better:\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_acc = val_acc\n",
    "            no_improve = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_f1': val_f1,\n",
    "                'val_acc': val_acc,\n",
    "            }, \"best_model.pth\")\n",
    "            print(f\"  âœ“ Saved best model (val F1={best_val_f1:.4f}, Acc={best_val_acc:.4f})\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= PATIENCE:\n",
    "                print(f\"\\nEarly stopping triggered (no improvement for {PATIENCE} epochs)\")\n",
    "                break\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LOADING BEST MODEL FOR FINAL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if os.path.exists(\"best_model.pth\"):\n",
    "        checkpoint = torch.load(\"best_model.pth\", map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "    all_preds, all_trues, all_probs = [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            Xv = Xv.to(DEVICE)\n",
    "            yv = yv.to(DEVICE)\n",
    "            logits = model(Xv)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    prec = precision_score(all_trues, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_trues, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "\n",
    "    print(\"\\n=== FINAL VALIDATION RESULTS ===\")\n",
    "    print(f\"Validation samples: {len(all_trues)}\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"\\nPrediction distribution: {dict(zip(*np.unique(all_preds, return_counts=True)))}\")\n",
    "    print(f\"True label distribution: {dict(zip(*np.unique(all_trues, return_counts=True)))}\")\n",
    "    print(f\"Probability range: [{min(all_probs):.3f}, {max(all_probs):.3f}]\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(\"              Predicted\")\n",
    "    print(\"              0(H)  1(P)\")\n",
    "    print(f\"Actual  0(H)  {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "    print(f\"        1(P)  {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "    \n",
    "    # Calculate specificity and sensitivity\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    print(f\"\\nSensitivity (Recall for Patient): {sensitivity:.4f}\")\n",
    "    print(f\"Specificity (Recall for Healthy): {specificity:.4f}\")\n",
    "    print(\"\\nModel saved to best_model.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7356b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "LR = 5e-4\n",
    "VAL_SPLIT = 0.2\n",
    "LSTM_HIDDEN = 64\n",
    "LSTM_LAYERS = 2\n",
    "DROPOUT = 0.45\n",
    "GRAD_CLIP = 1.0\n",
    "NUM_WORKERS = 0\n",
    "AUGMENT = True\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    def __init__(self, data_dir, folders=(\"healthy\",\"patient\"), augment=False):\n",
    "        self.augment = augment\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        idxs = np.argsort(self.files)\n",
    "        self.files = [self.files[i] for i in idxs]\n",
    "        self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.files[idx])  # shape (44,8,5,5,200)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[idx]} shape {arr.shape} != (44,8,5,5,200)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        \n",
    "        T, C, H, W, F = arr.shape\n",
    "        arr = arr.reshape(T, C*H*W, F)\n",
    "        \n",
    "        # Normalize per channel across time\n",
    "        mean = arr.mean(axis=(0, 2), keepdims=True)\n",
    "        std = arr.std(axis=(0, 2), keepdims=True) + 1e-6\n",
    "        arr = (arr - mean) / std\n",
    "        \n",
    "        # Average across the channel dimension\n",
    "        arr = arr.mean(axis=1)  # (44, 200)\n",
    "        \n",
    "        # Augmentation\n",
    "        if self.augment:\n",
    "            noise_std = np.random.uniform(0.015, 0.04)\n",
    "            arr += np.random.normal(0, noise_std, arr.shape).astype(np.float32)\n",
    "            scale = np.random.uniform(0.92, 1.08)\n",
    "            arr *= scale\n",
    "            if np.random.rand() > 0.5:\n",
    "                shift = np.random.randint(-3, 4)\n",
    "                arr = np.roll(arr, shift, axis=0)\n",
    "        \n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class ImprovedLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=200, hidden_size=LSTM_HIDDEN, num_layers=LSTM_LAYERS, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        lstm_output_size = hidden_size * 2\n",
    "        \n",
    "        self.attention_weights = nn.Linear(lstm_output_size, 1)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_size, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.7),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif 'weight' in name and param.dim() >= 2:\n",
    "                nn.init.kaiming_normal_(param.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attn_scores = self.attention_weights(lstm_out)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)\n",
    "        logits = self.classifier(context).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Loss ----------------\n",
    "class LabelSmoothingBCELoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.pos_weight = pos_weight\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        targets = targets * (1 - self.smoothing) + self.smoothing / 2\n",
    "        return nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=self.pos_weight\n",
    "        )\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def prepare_loaders(data_dir):\n",
    "    full_ds = EEGFileDataset(data_dir, augment=False)\n",
    "    indices = np.arange(len(full_ds))\n",
    "    labels = np.array([full_ds[i][1].item() for i in range(len(full_ds))])\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=VAL_SPLIT, stratify=labels, random_state=SEED\n",
    "    )\n",
    "    \n",
    "    train_ds_aug = EEGFileDataset(data_dir, augment=True)\n",
    "    train_ds = torch.utils.data.Subset(train_ds_aug, train_idx)\n",
    "    val_ds = torch.utils.data.Subset(full_ds, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "        num_workers=NUM_WORKERS, drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    train_labels = labels[train_idx]\n",
    "    neg = (train_labels == 0).sum()\n",
    "    pos = (train_labels == 1).sum()\n",
    "    pos_weight = torch.tensor([neg / (pos + 1e-12)], dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Dataset Info ===\")\n",
    "    print(f\"Total files: {len(full_ds)}\")\n",
    "    print(f\"Train: {len(train_ds)} (Healthy={neg}, Patient={pos})\")\n",
    "    print(f\"Val: {len(val_ds)}\")\n",
    "    print(f\"Pos_weight: {pos_weight.item():.3f}\")\n",
    "    print(f\"Class distribution in train: {neg/(neg+pos)*100:.1f}% healthy, {pos/(neg+pos)*100:.1f}% patient\\n\")\n",
    "    \n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Train & Evaluate ----------------\n",
    "def train_and_evaluate():\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders(DATA_DIR)\n",
    "    model = ImprovedLSTMModel().to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Model Info ===\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\\n\")\n",
    "    \n",
    "    criterion = LabelSmoothingBCELoss(smoothing=0.1, pos_weight=pos_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "\n",
    "    best_val_f1 = 0.0\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_trues = [], []\n",
    "        \n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} - train\", leave=False):\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            train_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            train_trues.extend(y.cpu().numpy().astype(int).tolist())\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_trues = [], []\n",
    "        val_probs_all = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in val_loader:\n",
    "                Xv = Xv.to(DEVICE)\n",
    "                yv = yv.to(DEVICE).float()\n",
    "                logits = model(Xv)\n",
    "                loss = criterion(logits, yv)\n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                val_probs_all.extend(probs.tolist())\n",
    "                val_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "                val_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        # Metrics\n",
    "        avg_train = float(np.mean(train_losses))\n",
    "        avg_val = float(np.mean(val_losses))\n",
    "        \n",
    "        train_acc = accuracy_score(train_trues, train_preds)\n",
    "        train_f1 = f1_score(train_trues, train_preds, zero_division=0)\n",
    "        \n",
    "        val_acc = accuracy_score(val_trues, val_preds)\n",
    "        val_prec = precision_score(val_trues, val_preds, zero_division=0)\n",
    "        val_rec = recall_score(val_trues, val_preds, zero_division=0)\n",
    "        val_f1 = f1_score(val_trues, val_preds, zero_division=0)\n",
    "        \n",
    "        unique_preds = np.unique(val_preds)\n",
    "        pred_dist = {int(p): val_preds.count(p) for p in unique_preds}\n",
    "        \n",
    "        print(f\"\\n[Epoch {epoch}/{EPOCHS}]\")\n",
    "        print(f\"  Train: Loss={avg_train:.4f}, Acc={train_acc:.4f}, F1={train_f1:.4f}\")\n",
    "        print(f\"  Val:   Loss={avg_val:.4f}, Acc={val_acc:.4f}, Prec={val_prec:.4f}, Rec={val_rec:.4f}, F1={val_f1:.4f}\")\n",
    "        print(f\"  Val predictions dist: {pred_dist}\")\n",
    "        print(f\"  Val prob range: [{min(val_probs_all):.3f}, {max(val_probs_all):.3f}]\")\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        is_better = (val_f1 > best_val_f1 + 1e-4) or \\\n",
    "                    (abs(val_f1 - best_val_f1) < 1e-4 and val_acc > best_val_acc)\n",
    "        \n",
    "        if is_better:\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_f1': val_f1,\n",
    "                'val_acc': val_acc,\n",
    "            }, \"best_model.pth\")\n",
    "            print(f\"  âœ“ Saved best model (val F1={best_val_f1:.4f}, Acc={best_val_acc:.4f})\")\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LOADING BEST MODEL FOR FINAL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if os.path.exists(\"best_model.pth\"):\n",
    "        checkpoint = torch.load(\"best_model.pth\", map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "    all_preds, all_trues, all_probs = [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            Xv = Xv.to(DEVICE)\n",
    "            yv = yv.to(DEVICE)\n",
    "            logits = model(Xv)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    prec = precision_score(all_trues, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_trues, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "\n",
    "    print(\"\\n=== FINAL VALIDATION RESULTS ===\")\n",
    "    print(f\"Validation samples: {len(all_trues)}\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"\\nPrediction distribution: {dict(zip(*np.unique(all_preds, return_counts=True)))}\")\n",
    "    print(f\"True label distribution: {dict(zip(*np.unique(all_trues, return_counts=True)))}\")\n",
    "    print(f\"Probability range: [{min(all_probs):.3f}, {max(all_probs):.3f}]\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(\"              Predicted\")\n",
    "    print(\"              0(H)  1(P)\")\n",
    "    print(f\"Actual  0(H)  {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "    print(f\"        1(P)  {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    print(f\"\\nSensitivity (Recall for Patient): {sensitivity:.4f}\")\n",
    "    print(f\"Specificity (Recall for Healthy): {specificity:.4f}\")\n",
    "    print(\"\\nModel saved to best_model.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cada2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 4  # Reduced for better generalization\n",
    "EPOCHS = 150\n",
    "LR = 1e-4  # Lower learning rate\n",
    "VAL_SPLIT = 0.2\n",
    "LSTM_HIDDEN = 128  # Increased capacity\n",
    "LSTM_LAYERS = 3\n",
    "DROPOUT = 0.3  # Reduced dropout\n",
    "GRAD_CLIP = 0.5\n",
    "NUM_WORKERS = 0\n",
    "EARLY_STOP_PATIENCE = 25\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    def __init__(self, data_dir, folders=(\"healthy\",\"patient\"), augment=False):\n",
    "        self.augment = augment\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        idxs = np.argsort(self.files)\n",
    "        self.files = [self.files[i] for i in idxs]\n",
    "        self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.files[idx])  # shape (44,8,5,5,200)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[idx]} shape {arr.shape} != (44,8,5,5,200)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        \n",
    "        T, C, H, W, F = arr.shape\n",
    "        arr = arr.reshape(T, C*H*W, F)\n",
    "        \n",
    "        # More robust normalization: per-sample z-score\n",
    "        arr_flat = arr.reshape(-1, F)\n",
    "        mean = arr_flat.mean(axis=0, keepdims=True)\n",
    "        std = arr_flat.std(axis=0, keepdims=True) + 1e-8\n",
    "        arr = (arr - mean) / std\n",
    "        \n",
    "        # Average across spatial channels\n",
    "        arr = arr.mean(axis=1)  # (44, 200)\n",
    "        \n",
    "        # Controlled augmentation only for training\n",
    "        if self.augment:\n",
    "            # Gaussian noise\n",
    "            if np.random.rand() > 0.5:\n",
    "                noise_std = np.random.uniform(0.01, 0.03)\n",
    "                arr += np.random.normal(0, noise_std, arr.shape).astype(np.float32)\n",
    "            \n",
    "            # Time masking\n",
    "            if np.random.rand() > 0.7:\n",
    "                mask_len = np.random.randint(1, 4)\n",
    "                mask_start = np.random.randint(0, T - mask_len)\n",
    "                arr[mask_start:mask_start+mask_len] = 0\n",
    "            \n",
    "            # Frequency masking\n",
    "            if np.random.rand() > 0.7:\n",
    "                mask_len = np.random.randint(5, 15)\n",
    "                mask_start = np.random.randint(0, F - mask_len)\n",
    "                arr[:, mask_start:mask_start+mask_len] = 0\n",
    "        \n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class AdvancedLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=200, hidden_size=LSTM_HIDDEN, num_layers=LSTM_LAYERS, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.LayerNorm(input_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        lstm_output_size = hidden_size * 2\n",
    "        \n",
    "        # Multi-head attention mechanism\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=lstm_output_size,\n",
    "            num_heads=4,\n",
    "            dropout=dropout * 0.5,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Classifier with skip connections\n",
    "        self.fc1 = nn.Linear(lstm_output_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(dropout * 0.7)\n",
    "        \n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.dropout3 = nn.Dropout(dropout * 0.5)\n",
    "        \n",
    "        self.fc_out = nn.Linear(64, 1)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif 'weight' in name and param.dim() >= 2:\n",
    "                nn.init.kaiming_normal_(param.data, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input projection\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # LSTM encoding\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Self-attention\n",
    "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        \n",
    "        # Global pooling: max + mean\n",
    "        max_pool = torch.max(attn_out, dim=1)[0]\n",
    "        mean_pool = torch.mean(attn_out, dim=1)\n",
    "        combined = max_pool + mean_pool\n",
    "        \n",
    "        # Classification layers\n",
    "        x = self.fc1(combined)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        logits = self.fc_out(x).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Loss with focal component ----------------\n",
    "class ImprovedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        # Focal loss to handle class imbalance\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=self.pos_weight, reduction='none'\n",
    "        )\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt = torch.where(targets == 1, probs, 1 - probs)\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "        alpha_weight = torch.where(targets == 1, self.alpha, 1 - self.alpha)\n",
    "        loss = alpha_weight * focal_weight * bce_loss\n",
    "        return loss.mean()\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def prepare_loaders(data_dir):\n",
    "    full_ds = EEGFileDataset(data_dir, augment=False)\n",
    "    indices = np.arange(len(full_ds))\n",
    "    labels = np.array([full_ds[i][1].item() for i in range(len(full_ds))])\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=VAL_SPLIT, stratify=labels, random_state=SEED\n",
    "    )\n",
    "    \n",
    "    train_ds_aug = EEGFileDataset(data_dir, augment=True)\n",
    "    train_ds = torch.utils.data.Subset(train_ds_aug, train_idx)\n",
    "    val_ds = torch.utils.data.Subset(full_ds, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "        num_workers=NUM_WORKERS, drop_last=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    train_labels = labels[train_idx]\n",
    "    neg = (train_labels == 0).sum()\n",
    "    pos = (train_labels == 1).sum()\n",
    "    # Balanced pos_weight\n",
    "    pos_weight = torch.tensor([neg / (pos + 1e-12)], dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Dataset Info ===\")\n",
    "    print(f\"Total files: {len(full_ds)}\")\n",
    "    print(f\"Train: {len(train_ds)} (Healthy={neg}, Patient={pos})\")\n",
    "    print(f\"Val: {len(val_ds)}\")\n",
    "    print(f\"Pos_weight: {pos_weight.item():.3f}\")\n",
    "    print(f\"Class distribution in train: {neg/(neg+pos)*100:.1f}% healthy, {pos/(neg+pos)*100:.1f}% patient\\n\")\n",
    "    \n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Train & Evaluate ----------------\n",
    "def train_and_evaluate():\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders(DATA_DIR)\n",
    "    model = AdvancedLSTMModel().to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Model Info ===\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\\n\")\n",
    "    \n",
    "    criterion = ImprovedLoss(alpha=0.25, gamma=2.0, pos_weight=pos_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    \n",
    "    # ReduceLROnPlateau for adaptive learning\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=10, min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_val_f1 = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_trues = [], []\n",
    "        \n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} - train\", leave=False):\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            train_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            train_trues.extend(y.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_trues = [], []\n",
    "        val_probs_all = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in val_loader:\n",
    "                Xv = Xv.to(DEVICE)\n",
    "                yv = yv.to(DEVICE).float()\n",
    "                logits = model(Xv)\n",
    "                loss = criterion(logits, yv)\n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                val_probs_all.extend(probs.tolist())\n",
    "                val_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "                val_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        # Metrics\n",
    "        avg_train = float(np.mean(train_losses))\n",
    "        avg_val = float(np.mean(val_losses))\n",
    "        \n",
    "        train_acc = accuracy_score(train_trues, train_preds)\n",
    "        train_f1 = f1_score(train_trues, train_preds, zero_division=0)\n",
    "        \n",
    "        val_acc = accuracy_score(val_trues, val_preds)\n",
    "        val_prec = precision_score(val_trues, val_preds, zero_division=0)\n",
    "        val_rec = recall_score(val_trues, val_preds, zero_division=0)\n",
    "        val_f1 = f1_score(val_trues, val_preds, zero_division=0)\n",
    "        \n",
    "        unique_preds = np.unique(val_preds)\n",
    "        pred_dist = {int(p): val_preds.count(p) for p in unique_preds}\n",
    "        \n",
    "        print(f\"\\n[Epoch {epoch}/{EPOCHS}]\")\n",
    "        print(f\"  Train: Loss={avg_train:.4f}, Acc={train_acc:.4f}, F1={train_f1:.4f}\")\n",
    "        print(f\"  Val:   Loss={avg_val:.4f}, Acc={val_acc:.4f}, Prec={val_prec:.4f}, Rec={val_rec:.4f}, F1={val_f1:.4f}\")\n",
    "        print(f\"  Val predictions dist: {pred_dist}\")\n",
    "        print(f\"  Val prob range: [{min(val_probs_all):.3f}, {max(val_probs_all):.3f}]\")\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        # Update scheduler\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        # Save best model based on accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_val_f1 = val_f1\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'val_f1': val_f1,\n",
    "            }, \"best_model.pth\")\n",
    "            print(f\"  âœ“ Saved best model (val Acc={best_val_acc:.4f}, F1={best_val_f1:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"\\nEarly stopping triggered (no improvement for {EARLY_STOP_PATIENCE} epochs)\")\n",
    "            break\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LOADING BEST MODEL FOR FINAL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if os.path.exists(\"best_model.pth\"):\n",
    "        checkpoint = torch.load(\"best_model.pth\", map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "    all_preds, all_trues, all_probs = [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            Xv = Xv.to(DEVICE)\n",
    "            yv = yv.to(DEVICE)\n",
    "            logits = model(Xv)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    prec = precision_score(all_trues, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_trues, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "\n",
    "    print(\"\\n=== FINAL VALIDATION RESULTS ===\")\n",
    "    print(f\"Validation samples: {len(all_trues)}\")\n",
    "    print(f\"Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"\\nPrediction distribution: {dict(zip(*np.unique(all_preds, return_counts=True)))}\")\n",
    "    print(f\"True label distribution: {dict(zip(*np.unique(all_trues, return_counts=True)))}\")\n",
    "    print(f\"Probability range: [{min(all_probs):.3f}, {max(all_probs):.3f}]\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(\"              Predicted\")\n",
    "    print(\"              0(H)  1(P)\")\n",
    "    print(f\"Actual  0(H)  {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "    print(f\"        1(P)  {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    print(f\"\\nSensitivity (Recall for Patient): {sensitivity:.4f}\")\n",
    "    print(f\"Specificity (Recall for Healthy): {specificity:.4f}\")\n",
    "    \n",
    "    if acc >= 0.90:\n",
    "        print(f\"\\nðŸŽ‰ SUCCESS! Achieved {acc*100:.2f}% validation accuracy (target: 90%)\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Current accuracy: {acc*100:.2f}% - Continue training or adjust hyperparameters\")\n",
    "    \n",
    "    print(\"\\nModel saved to best_model.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 2  # Very small batch for tiny dataset\n",
    "EPOCHS = 200\n",
    "LR = 5e-5  # Very low learning rate\n",
    "VAL_SPLIT = 0.2\n",
    "LSTM_HIDDEN = 256  # Increased capacity\n",
    "LSTM_LAYERS = 2  # Reduced to prevent overfitting\n",
    "DROPOUT = 0.2  # Lower dropout\n",
    "GRAD_CLIP = 1.0\n",
    "NUM_WORKERS = 0\n",
    "EARLY_STOP_PATIENCE = 40\n",
    "NUM_FOLDS = 5  # K-fold cross-validation\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    def __init__(self, data_dir, folders=(\"healthy\",\"patient\"), augment=False, aug_factor=1):\n",
    "        self.augment = augment\n",
    "        self.aug_factor = aug_factor\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        idxs = np.argsort(self.files)\n",
    "        self.files = [self.files[i] for i in idxs]\n",
    "        self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files) * self.aug_factor if self.augment else len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = idx % len(self.files)\n",
    "        arr = np.load(self.files[real_idx])  # shape (44,8,5,5,200)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[real_idx]} shape {arr.shape} != (44,8,5,5,200)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        \n",
    "        T, C, H, W, F = arr.shape\n",
    "        \n",
    "        # Process each channel separately then combine\n",
    "        arr = arr.reshape(T, C*H*W, F)\n",
    "        \n",
    "        # Robust normalization\n",
    "        mean = arr.mean(axis=(0, 2), keepdims=True)\n",
    "        std = arr.std(axis=(0, 2), keepdims=True) + 1e-8\n",
    "        arr = (arr - mean) / std\n",
    "        \n",
    "        # Aggregate spatial channels\n",
    "        arr = arr.mean(axis=1)  # (44, 200)\n",
    "        \n",
    "        # Stronger augmentation for small dataset\n",
    "        if self.augment:\n",
    "            # Random noise\n",
    "            if np.random.rand() > 0.3:\n",
    "                noise_std = np.random.uniform(0.02, 0.05)\n",
    "                arr += np.random.normal(0, noise_std, arr.shape).astype(np.float32)\n",
    "            \n",
    "            # Random amplitude scaling\n",
    "            if np.random.rand() > 0.3:\n",
    "                scale = np.random.uniform(0.85, 1.15)\n",
    "                arr *= scale\n",
    "            \n",
    "            # Time shift\n",
    "            if np.random.rand() > 0.5:\n",
    "                shift = np.random.randint(-5, 6)\n",
    "                arr = np.roll(arr, shift, axis=0)\n",
    "            \n",
    "            # Time warping\n",
    "            if np.random.rand() > 0.6:\n",
    "                warp_factor = np.random.uniform(0.9, 1.1)\n",
    "                new_len = int(T * warp_factor)\n",
    "                indices = np.linspace(0, T-1, new_len)\n",
    "                arr_warped = np.zeros((new_len, F), dtype=np.float32)\n",
    "                for i in range(new_len):\n",
    "                    idx = int(indices[i])\n",
    "                    arr_warped[i] = arr[idx]\n",
    "                if new_len > T:\n",
    "                    arr = arr_warped[:T]\n",
    "                else:\n",
    "                    arr = np.pad(arr_warped, ((0, T-new_len), (0, 0)), mode='edge')\n",
    "            \n",
    "            # Frequency masking\n",
    "            if np.random.rand() > 0.5:\n",
    "                mask_len = np.random.randint(10, 30)\n",
    "                mask_start = np.random.randint(0, max(1, F - mask_len))\n",
    "                arr[:, mask_start:mask_start+mask_len] *= np.random.uniform(0.1, 0.3)\n",
    "        \n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[real_idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class DeepLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=200, hidden_size=LSTM_HIDDEN, num_layers=LSTM_LAYERS, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature extraction\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.LayerNorm(input_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.3)\n",
    "        )\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        lstm_output_size = hidden_size * 2\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention_query = nn.Linear(lstm_output_size, lstm_output_size)\n",
    "        self.attention_key = nn.Linear(lstm_output_size, lstm_output_size)\n",
    "        self.attention_value = nn.Linear(lstm_output_size, lstm_output_size)\n",
    "        \n",
    "        # Deep classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_size * 2, 512),  # *2 for max+mean pooling\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.8),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.6),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.4),\n",
    "            \n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                param.data.fill_(0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif 'weight' in name and param.dim() >= 2:\n",
    "                nn.init.kaiming_normal_(param.data, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        x = self.feature_extractor(x)\n",
    "        \n",
    "        # LSTM encoding\n",
    "        lstm_out, _ = self.lstm(x)  # (batch, seq, hidden*2)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        Q = self.attention_query(lstm_out)\n",
    "        K = self.attention_key(lstm_out)\n",
    "        V = self.attention_value(lstm_out)\n",
    "        \n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(lstm_out.size(-1))\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "        attended = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        # Multi-scale pooling\n",
    "        max_pool = torch.max(attended, dim=1)[0]\n",
    "        mean_pool = torch.mean(attended, dim=1)\n",
    "        combined = torch.cat([max_pool, mean_pool], dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(combined).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Mixup augmentation ----------------\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ---------------- Loss ----------------\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=self.pos_weight, reduction='none'\n",
    "        )\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt = torch.where(targets == 1, probs, 1 - probs)\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "        alpha_weight = torch.where(targets == 1, self.alpha, 1 - self.alpha)\n",
    "        loss = alpha_weight * focal_weight * bce_loss\n",
    "        return loss.mean()\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def prepare_loaders_kfold(data_dir, fold_idx=0):\n",
    "    full_ds = EEGFileDataset(data_dir, augment=False)\n",
    "    indices = np.arange(len(full_ds))\n",
    "    labels = np.array([full_ds[i][1].item() for i in range(len(full_ds))])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "    splits = list(skf.split(indices, labels))\n",
    "    train_idx, val_idx = splits[fold_idx]\n",
    "    \n",
    "    # Create augmented training dataset\n",
    "    train_ds_aug = EEGFileDataset(data_dir, augment=True, aug_factor=5)  # 5x augmentation\n",
    "    train_ds = torch.utils.data.Subset(train_ds_aug, train_idx)\n",
    "    val_ds = torch.utils.data.Subset(full_ds, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "        num_workers=NUM_WORKERS, drop_last=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    train_labels = labels[train_idx]\n",
    "    neg = (train_labels == 0).sum()\n",
    "    pos = (train_labels == 1).sum()\n",
    "    pos_weight = torch.tensor([neg / (pos + 1e-12)], dtype=torch.float32).to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Fold {fold_idx+1}/{NUM_FOLDS} Dataset Info ===\")\n",
    "    print(f\"Train: {len(train_idx)} (Healthy={neg}, Patient={pos})\")\n",
    "    print(f\"Val: {len(val_idx)}\")\n",
    "    print(f\"Pos_weight: {pos_weight.item():.3f}\\n\")\n",
    "    \n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Train & Evaluate ----------------\n",
    "def train_fold(fold_idx=0):\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders_kfold(DATA_DIR, fold_idx)\n",
    "    model = DeepLSTMModel().to(DEVICE)\n",
    "    \n",
    "    print(f\"\\n=== Model Info ===\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2.0, pos_weight=pos_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=5e-5)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=20, T_mult=2, eta_min=1e-7\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_trues = [], []\n",
    "        \n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False):\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).float()\n",
    "            \n",
    "            # Apply mixup\n",
    "            if np.random.rand() > 0.5 and X.size(0) > 1:\n",
    "                X_mixed, y_a, y_b, lam = mixup_data(X, y, alpha=0.2)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(X_mixed)\n",
    "                loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            train_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            train_trues.extend(y.cpu().numpy().astype(int).tolist())\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_trues = [], []\n",
    "        val_probs_all = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in val_loader:\n",
    "                Xv = Xv.to(DEVICE)\n",
    "                yv = yv.to(DEVICE).float()\n",
    "                logits = model(Xv)\n",
    "                loss = criterion(logits, yv)\n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                val_probs_all.extend(probs.tolist())\n",
    "                val_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "                val_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        # Metrics\n",
    "        avg_train = float(np.mean(train_losses))\n",
    "        avg_val = float(np.mean(val_losses))\n",
    "        \n",
    "        train_acc = accuracy_score(train_trues, train_preds)\n",
    "        val_acc = accuracy_score(val_trues, val_preds)\n",
    "        val_f1 = f1_score(val_trues, val_preds, zero_division=0)\n",
    "        \n",
    "        if epoch % 10 == 0 or val_acc > best_val_acc:\n",
    "            print(f\"\\n[Epoch {epoch}/{EPOCHS}]\")\n",
    "            print(f\"  Train: Loss={avg_train:.4f}, Acc={train_acc:.4f}\")\n",
    "            print(f\"  Val:   Loss={avg_val:.4f}, Acc={val_acc:.4f}, F1={val_f1:.4f}\")\n",
    "            print(f\"  Prob range: [{min(val_probs_all):.3f}, {max(val_probs_all):.3f}]\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "            }, f\"best_model_fold{fold_idx}.pth\")\n",
    "            print(f\"  âœ“ Best acc: {best_val_acc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    # Load best and evaluate\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold_idx}.pth\", map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    all_preds, all_trues = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            Xv = Xv.to(DEVICE)\n",
    "            logits = model(Xv)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "\n",
    "    print(f\"\\n=== Fold {fold_idx+1} Final Results ===\")\n",
    "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    return acc, f1, cm\n",
    "\n",
    "def train_and_evaluate():\n",
    "    print(\"=\"*60)\n",
    "    print(\"STARTING K-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    all_accs = []\n",
    "    all_f1s = []\n",
    "    \n",
    "    for fold in range(NUM_FOLDS):\n",
    "        acc, f1, cm = train_fold(fold)\n",
    "        all_accs.append(acc)\n",
    "        all_f1s.append(f1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Mean Accuracy: {np.mean(all_accs):.4f} Â± {np.std(all_accs):.4f}\")\n",
    "    print(f\"Mean F1-score: {np.mean(all_f1s):.4f} Â± {np.std(all_f1s):.4f}\")\n",
    "    print(f\"Individual fold accuracies: {[f'{a:.4f}' for a in all_accs]}\")\n",
    "    \n",
    "    if np.mean(all_accs) >= 0.90:\n",
    "        print(f\"\\nðŸŽ‰ SUCCESS! Achieved {np.mean(all_accs)*100:.2f}% average accuracy!\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Current: {np.mean(all_accs)*100:.2f}% - Try adjusting hyperparameters\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16  # Larger batch for stability\n",
    "EPOCHS = 300\n",
    "LR = 1e-3  # Higher learning rate\n",
    "VAL_SPLIT = 0.2\n",
    "LSTM_HIDDEN = 64\n",
    "LSTM_LAYERS = 1  # Simpler model\n",
    "DROPOUT = 0.5\n",
    "GRAD_CLIP = 5.0\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    def __init__(self, data_dir, folders=(\"healthy\",\"patient\"), augment=False):\n",
    "        self.augment = augment\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        idxs = np.argsort(self.files)\n",
    "        self.files = [self.files[i] for i in idxs]\n",
    "        self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.files[idx])  # shape (44,8,5,5,200)\n",
    "        arr = arr.astype(np.float32)\n",
    "        \n",
    "        T, C, H, W, F = arr.shape\n",
    "        \n",
    "        # Simple flattening and aggregation\n",
    "        arr = arr.reshape(T, C*H*W, F)\n",
    "        arr = arr.mean(axis=1)  # (44, 200)\n",
    "        \n",
    "        # Simple standardization\n",
    "        arr = (arr - arr.mean()) / (arr.std() + 1e-8)\n",
    "        \n",
    "        # Minimal augmentation\n",
    "        if self.augment and np.random.rand() > 0.5:\n",
    "            noise = np.random.normal(0, 0.05, arr.shape).astype(np.float32)\n",
    "            arr = arr + noise\n",
    "        \n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- Simple LSTM Model ----------------\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size=200, hidden_size=64, num_layers=1, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Simple classifier\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Use last timestep\n",
    "        last_out = lstm_out[:, -1, :]\n",
    "        logits = self.fc(last_out).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Prepare Data ----------------\n",
    "def prepare_loaders(data_dir):\n",
    "    full_ds = EEGFileDataset(data_dir, augment=False)\n",
    "    indices = np.arange(len(full_ds))\n",
    "    labels = np.array([full_ds[i][1].item() for i in range(len(full_ds))])\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=VAL_SPLIT, stratify=labels, random_state=SEED\n",
    "    )\n",
    "    \n",
    "    train_ds_aug = EEGFileDataset(data_dir, augment=True)\n",
    "    train_ds = torch.utils.data.Subset(train_ds_aug, train_idx)\n",
    "    val_ds = torch.utils.data.Subset(full_ds, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    train_labels = labels[train_idx]\n",
    "    neg = (train_labels == 0).sum()\n",
    "    pos = (train_labels == 1).sum()\n",
    "    \n",
    "    print(f\"\\n=== Dataset Info ===\")\n",
    "    print(f\"Total: {len(full_ds)} | Train: {len(train_ds)} | Val: {len(val_ds)}\")\n",
    "    print(f\"Train distribution: Healthy={neg}, Patient={pos}\")\n",
    "    print(f\"Val distribution: Healthy={(labels[val_idx]==0).sum()}, Patient={(labels[val_idx]==1).sum()}\\n\")\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# ---------------- Train ----------------\n",
    "def train_and_evaluate():\n",
    "    train_loader, val_loader = prepare_loaders(DATA_DIR)\n",
    "    model = SimpleLSTM().to(DEVICE)\n",
    "    \n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=20, min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    no_improve = 0\n",
    "    \n",
    "    print(\"Starting training...\\n\")\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * X.size(0)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            train_correct += (preds == y).sum().item()\n",
    "            train_total += X.size(0)\n",
    "\n",
    "        train_acc = train_correct / train_total\n",
    "        train_loss = train_loss / train_total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_trues = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                X, y = X.to(DEVICE), y.to(DEVICE).float()\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "                val_loss += loss.item() * X.size(0)\n",
    "                \n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                val_preds.extend(preds.cpu().numpy().tolist())\n",
    "                val_trues.extend(y.cpu().numpy().tolist())\n",
    "\n",
    "        val_loss = val_loss / len(val_trues)\n",
    "        val_acc = accuracy_score(val_trues, val_preds)\n",
    "        val_f1 = f1_score(val_trues, val_preds, zero_division=0)\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Print progress\n",
    "        if epoch % 10 == 0 or val_acc > best_val_acc:\n",
    "            print(f\"Epoch {epoch:3d}/{EPOCHS} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f} | \"\n",
    "                  f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Save best\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "            }, \"best_model.pth\")\n",
    "            print(f\"  âœ“ New best: {best_val_acc:.4f}\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            \n",
    "        if no_improve >= 50:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    checkpoint = torch.load(\"best_model.pth\", map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']}\\n\")\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_trues, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X = X.to(DEVICE)\n",
    "            logits = model(X)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(y.numpy().tolist())\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    prec = precision_score(all_trues, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_trues, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "\n",
    "    print(f\"Validation samples: {len(all_trues)}\")\n",
    "    print(f\"Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"\\nPrediction distribution: {dict(zip(*np.unique(all_preds, return_counts=True)))}\")\n",
    "    print(f\"True label distribution: {dict(zip(*np.unique(all_trues, return_counts=True)))}\")\n",
    "    print(f\"Probability range: [{min(all_probs):.3f}, {max(all_probs):.3f}]\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(\"              Predicted\")\n",
    "    print(\"              0(H)  1(P)\")\n",
    "    print(f\"Actual  0(H)  {cm[0,0]:4d}  {cm[0,1]:4d}\")\n",
    "    print(f\"        1(P)  {cm[1,0]:4d}  {cm[1,1]:4d}\")\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    print(f\"\\nSensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    \n",
    "    if acc >= 0.90:\n",
    "        print(f\"\\nðŸŽ‰ SUCCESS! Achieved {acc*100:.2f}% accuracy!\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Current: {acc*100:.2f}% - Data may have limited separability\")\n",
    "    \n",
    "    # Diagnostic info\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DIAGNOSTIC INFORMATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"If accuracy is still low, possible issues:\")\n",
    "    print(\"1. Data quality: Check if EEG signals are properly preprocessed\")\n",
    "    print(\"2. Class overlap: Healthy and patient signals may be too similar\")\n",
    "    print(\"3. Sample size: 91 samples is very small for deep learning\")\n",
    "    print(\"4. Feature extraction: The (44,8,5,5,200) structure may need better processing\")\n",
    "    print(\"\\nRecommendations:\")\n",
    "    print(\"- Try extracting domain-specific features (frequency bands, entropy, etc.)\")\n",
    "    print(\"- Use classical ML (Random Forest, SVM) as baseline\")\n",
    "    print(\"- Collect more data if possible\")\n",
    "    print(\"- Verify data labels are correct\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab649222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# improved_cnn_lstm_eeg.py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 4         # slightly larger if possible\n",
    "EPOCHS = 80            # reduced from 200\n",
    "LR = 3e-4\n",
    "NUM_WORKERS = 0\n",
    "EARLY_STOP_PATIENCE = 20\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "F_EMB = 16             # frequency embedding size (reduces 200 -> 16)\n",
    "CONV_OUT = 64          # conv output channels\n",
    "LSTM_HIDDEN = 128\n",
    "LSTM_LAYERS = 1\n",
    "DROPOUT = 0.2\n",
    "GRAD_CLIP = 1.0\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    def _init_(self, data_dir, folders=(\"healthy\",\"patient\"), augment=False, aug_factor=1):\n",
    "        self.augment = augment\n",
    "        self.aug_factor = aug_factor\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        # stable ordering\n",
    "        idxs = np.argsort(self.files)\n",
    "        self.files = [self.files[i] for i in idxs]\n",
    "        self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.files) * self.aug_factor if self.augment else len(self.files)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        real_idx = idx % len(self.files)\n",
    "        arr = np.load(self.files[real_idx])  # expected shape (T, C, H, W, F)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[real_idx]} shape {arr.shape} != (T,C,H,W,F)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        T, C, H, W, F = arr.shape\n",
    "\n",
    "        # Normalize per-sample across (time, channels, spatial, freq)\n",
    "        mean = arr.mean(axis=(0,1,2,3,4), keepdims=True)  # scalar\n",
    "        std = arr.std(axis=(0,1,2,3,4), keepdims=True) + 1e-8\n",
    "        arr = (arr - mean) / std\n",
    "\n",
    "        # Data augmentation (same as your previous strong augmentations)\n",
    "        if self.augment:\n",
    "            # Temporal noise\n",
    "            if np.random.rand() > 0.3:\n",
    "                noise_std = np.random.uniform(0.01, 0.04)\n",
    "                arr += np.random.normal(0, noise_std, arr.shape).astype(np.float32)\n",
    "\n",
    "            # Amplitude scaling\n",
    "            if np.random.rand() > 0.3:\n",
    "                scale = np.random.uniform(0.9, 1.1)\n",
    "                arr *= scale\n",
    "\n",
    "            # Time shift\n",
    "            if np.random.rand() > 0.5:\n",
    "                shift = np.random.randint(-5, 6)\n",
    "                arr = np.roll(arr, shift, axis=0)\n",
    "\n",
    "            # Frequency masking\n",
    "            if np.random.rand() > 0.5:\n",
    "                mask_len = np.random.randint(10, 30)\n",
    "                mask_start = np.random.randint(0, max(1, F - mask_len))\n",
    "                arr[..., mask_start:mask_start+mask_len] *= np.random.uniform(0.05, 0.4)\n",
    "\n",
    "        # Return (T, C, H, W, F) as tensor\n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[real_idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class CNN_LSTM_Attention(nn.Module):\n",
    "    def _init_(self, in_freq=200, f_emb=F_EMB, conv_out=CONV_OUT,\n",
    "                 H=5, W=5, C=8, lstm_hidden=LSTM_HIDDEN, lstm_layers=LSTM_LAYERS,\n",
    "                 dropout=DROPOUT):\n",
    "        super()._init_()\n",
    "        self.f_emb = f_emb\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "\n",
    "        # 1) Frequency embedding applied per electrode (shared linear)\n",
    "        self.freq_emb = nn.Sequential(\n",
    "            nn.Linear(in_freq, f_emb),\n",
    "            nn.LayerNorm(f_emb),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        # 2) Conv2D to extract spatial features: input channels = C * f_emb\n",
    "        in_ch = C * f_emb\n",
    "        self.spatial_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, conv_out, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(conv_out),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(conv_out, conv_out, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(conv_out),\n",
    "            nn.GELU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1))  # produce (batch*time, conv_out, 1,1)\n",
    "        )\n",
    "\n",
    "        feat_dim = conv_out  # feature per time-step\n",
    "\n",
    "        # 3) LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=feat_dim,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "        lstm_out_size = lstm_hidden * 2\n",
    "\n",
    "        # 4) Attention (scaled dot-product)\n",
    "        self.att_q = nn.Linear(lstm_out_size, lstm_out_size)\n",
    "        self.att_k = nn.Linear(lstm_out_size, lstm_out_size)\n",
    "        self.att_v = nn.Linear(lstm_out_size, lstm_out_size)\n",
    "\n",
    "        # 5) Classifier (simpler)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_out_size * 2, 64),  # max+mean pooling\n",
    "            nn.LayerNorm(64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for n, p in self.named_parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.kaiming_normal_(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, T, C, H, W, F)\n",
    "        B, T, C, H, W, F = x.shape\n",
    "        # Step A: frequency embedding for each electrode separately\n",
    "        # reshape to (B*T*C, F)\n",
    "        x_freq = x.reshape(B * T * C, F)\n",
    "        x_emb = self.freq_emb(x_freq)  # -> (B*T*C, f_emb)\n",
    "        # reshape back: (B, T, C, f_emb)\n",
    "        x_emb = x_emb.view(B, T, C, -1)\n",
    "        # Now we want shape (B*T, C*f_emb, H, W) because conv expects channels & H/W\n",
    "        # But currently we lost H/W because embedded was per-electrode scalar - we must re-introduce H,W\n",
    "        # Original per-electrode had spatial H,W and freq F per (C,H,W). To maintain H/W,\n",
    "        # we should have applied the freq-embed per (C,H,W) location. Let's do that properly:\n",
    "        # NOTE: to be safe, if input had shape (B,T,C,H,W,F) --> reshape to (B*T*C*H*W, F) above would be needed.\n",
    "        # We'll re-implement correctly here:\n",
    "        x = x.permute(0,1,2,3,4,5).contiguous()  # ensure contiguous\n",
    "        x_reshape = x.view(B * T * C * H * W, F)            # (B*T*C*H*W, F)\n",
    "        x_femb = self.freq_emb(x_reshape)                   # (B*T*C*H*W, f_emb)\n",
    "        # restore to (B, T, C, H, W, f_emb)\n",
    "        x_femb = x_femb.view(B, T, C, H, W, -1)\n",
    "        # permute to (B, T, (C*f_emb), H, W)\n",
    "        x_per_time = x_femb.permute(0,1,2,5,3,4).contiguous()  # (B,T,C,f_emb,H,W)\n",
    "        Bp, Tp, Cp, Femb, Hp, Wp = x_per_time.shape\n",
    "        x_per_time = x_per_time.view(Bp * Tp, Cp * Femb, Hp, Wp)  # (B*T, C*f_emb, H, W)\n",
    "\n",
    "        # apply conv per time-step (we merged batch and time)\n",
    "        conv_out = self.spatial_conv(x_per_time)  # (B*T, conv_out, 1, 1)\n",
    "        conv_out = conv_out.view(B, T, -1)        # (B, T, conv_out)\n",
    "\n",
    "        # LSTM over time\n",
    "        lstm_out, _ = self.lstm(conv_out)  # (B, T, hidden*2)\n",
    "\n",
    "        # Attention\n",
    "        Q = self.att_q(lstm_out)\n",
    "        K = self.att_k(lstm_out)\n",
    "        V = self.att_v(lstm_out)\n",
    "        d = Q.size(-1)\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2,-1)) / (d ** 0.5)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attended = torch.matmul(attn_weights, V)  # (B, T, d)\n",
    "\n",
    "        # Pooling\n",
    "        max_pool = torch.max(attended, dim=1)[0]\n",
    "        mean_pool = torch.mean(attended, dim=1)\n",
    "        combined = torch.cat([max_pool, mean_pool], dim=1)  # (B, d*2)\n",
    "\n",
    "        logits = self.classifier(combined).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Mixup & Loss ----------------\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def _init_(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super()._init_()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        targets = targets.float()\n",
    "        bce = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=self.pos_weight, reduction='none'\n",
    "        )\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt = torch.where(targets == 1, probs, 1 - probs)\n",
    "        focal = (1 - pt) ** self.gamma\n",
    "        alpha_w = torch.where(targets == 1, self.alpha, 1 - self.alpha)\n",
    "        loss = alpha_w * focal * bce\n",
    "        return loss.mean()\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def prepare_loaders_kfold(data_dir, fold_idx=0):\n",
    "    full_ds = EEGFileDataset(data_dir, augment=False)\n",
    "    indices = np.arange(len(full_ds))\n",
    "    labels = np.array([full_ds[i][1].item() for i in range(len(full_ds))])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "    splits = list(skf.split(indices, labels))\n",
    "    train_idx, val_idx = splits[fold_idx]\n",
    "\n",
    "    train_ds_aug = EEGFileDataset(data_dir, augment=True, aug_factor=3)\n",
    "    # map train_idx into indices of augmented ds by keeping only original file indexes present in train_idx\n",
    "    # Since train_ds_aug repeats files, easiest is to create Subset from full non-aug ds for val,\n",
    "    # but for train we'll index into full dataset and wrap with augmentation:\n",
    "    # Simpler robust approach: build train dataset from file paths directly:\n",
    "    train_files = [full_ds.files[i] for i in train_idx]\n",
    "    train_labels = [int(full_ds.labels[i]) for i in train_idx]\n",
    "    # create small custom subset dataset:\n",
    "    class TempDataset(Dataset):\n",
    "        def _init_(self, file_list, label_list, augment=True, aug_factor=3):\n",
    "            self.files = file_list\n",
    "            self.labels = label_list\n",
    "            self.augment = augment\n",
    "            self.aug_factor = aug_factor\n",
    "        def _len_(self):\n",
    "            return len(self.files) * self.aug_factor if self.augment else len(self.files)\n",
    "        def _getitem_(self, idx):\n",
    "            ridx = idx % len(self.files)\n",
    "            arr = np.load(self.files[ridx]).astype(np.float32)\n",
    "            # minimal same normalization/augmentation as EEGFileDataset\n",
    "            mean = arr.mean()\n",
    "            std = arr.std() + 1e-8\n",
    "            arr = (arr - mean) / std\n",
    "            if self.augment:\n",
    "                if np.random.rand() > 0.5:\n",
    "                    arr += np.random.normal(0, 0.02, arr.shape).astype(np.float32)\n",
    "            return torch.from_numpy(arr), torch.tensor(self.labels[ridx], dtype=torch.long)\n",
    "    train_ds = TempDataset(train_files, train_labels, augment=True, aug_factor=3)\n",
    "    val_ds = torch.utils.data.Subset(full_ds, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, drop_last=False)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    neg = (np.array(train_labels) == 0).sum()\n",
    "    pos = (np.array(train_labels) == 1).sum()\n",
    "    pos_weight = torch.tensor([neg / (pos + 1e-12)], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "    print(f\"\\n=== Fold {fold_idx+1}/{NUM_FOLDS} Dataset Info ===\")\n",
    "    print(f\"Train files: {len(train_files)} (Healthy={neg}, Patient={pos})\")\n",
    "    print(f\"Val: {len(val_idx)}\")\n",
    "    print(f\"Pos_weight: {pos_weight.item():.3f}\\n\")\n",
    "\n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Train & Evaluate ----------------\n",
    "def train_fold(fold_idx=0):\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders_kfold(DATA_DIR, fold_idx)\n",
    "    # We'll create a model using shape assumptions but keep it flexible\n",
    "    # read one sample to get dims\n",
    "    sample_X, _ = next(iter(train_loader))\n",
    "    # sample_X shape is (B, T, C, H, W, F)\n",
    "    _, T, C, H, W, F = sample_X.shape\n",
    "    model = CNN_LSTM_Attention(in_freq=F, f_emb=F_EMB, conv_out=CONV_OUT,\n",
    "                               H=H, W=W, C=C, lstm_hidden=LSTM_HIDDEN,\n",
    "                               lstm_layers=LSTM_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
    "\n",
    "    print(f\"\\n=== Model Info (Fold {fold_idx}) ===\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Total params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2.0, pos_weight=pos_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience = 0\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        preds_tr = []\n",
    "        trues_tr = []\n",
    "\n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False):\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).float()\n",
    "            # occasionally mixup\n",
    "            if X.size(0) > 1 and np.random.rand() > 0.5:\n",
    "                X_m, ya, yb, lam = mixup_data(X, y, alpha=0.2)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(X_m)\n",
    "                loss = lam * criterion(logits, ya) + (1 - lam) * criterion(logits, yb)\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            preds_tr.extend((probs >= 0.5).astype(int).tolist())\n",
    "            trues_tr.extend(y.cpu().numpy().astype(int).tolist())\n",
    "        scheduler.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds = []\n",
    "        val_trues = []\n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in val_loader:\n",
    "                Xv = Xv.to(DEVICE)\n",
    "                yv = yv.to(DEVICE).float()\n",
    "                logits = model(Xv)\n",
    "                loss = criterion(logits, yv)\n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                val_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "                val_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        train_acc = accuracy_score(trues_tr, preds_tr) if len(trues_tr) > 0 else 0.0\n",
    "        val_acc = accuracy_score(val_trues, val_preds) if len(val_trues) > 0 else 0.0\n",
    "        val_f1 = f1_score(val_trues, val_preds, zero_division=0)\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Train Loss={np.mean(losses):.4f} TrainAcc={train_acc:.4f} | Val Loss={np.mean(val_losses):.4f} ValAcc={val_acc:.4f} ValF1={val_f1:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience = 0\n",
    "            torch.save({'epoch': epoch, 'model_state': model.state_dict(), 'val_acc': val_acc}, f\"best_model_fold{fold_idx}.pth\")\n",
    "            print(\"  -> saved best model\")\n",
    "        else:\n",
    "            patience += 1\n",
    "        if patience >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    # Load best and evaluate final on val set\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold_idx}.pth\", map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            Xv = Xv.to(DEVICE)\n",
    "            logits = model(Xv)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(yv.numpy().astype(int).tolist())\n",
    "    acc = accuracy_score(all_trues, all_preds)\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds)\n",
    "    print(f\"\\n=== Fold {fold_idx+1} Results === Acc: {acc:.4f} F1: {f1:.4f}\")\n",
    "    print(cm)\n",
    "    return acc, f1, cm\n",
    "\n",
    "def train_and_evaluate():\n",
    "    print(\"Starting k-fold training\")\n",
    "    accs, f1s = [], []\n",
    "    for fold in range(NUM_FOLDS):\n",
    "        acc, f1, cm = train_fold(fold)\n",
    "        accs.append(acc)\n",
    "        f1s.append(f1)\n",
    "    print(\"Cross-val finished\")\n",
    "    print(f\"Mean Acc: {np.mean(accs):.4f} Â± {np.std(accs):.4f}\")\n",
    "    print(f\"Mean F1 : {np.mean(f1s):.4f} Â± {np.std(f1s):.4f}\")\n",
    "\n",
    "if __name__ == \"_main_\":\n",
    "    train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# improved_eeg_cnn_lstm.py\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = \"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10      # keep small first to confirm output\n",
    "LR = 5e-4\n",
    "NUM_FOLDS = 5\n",
    "WINDOW_SIZE = 20\n",
    "WINDOW_STRIDE = 10\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "# ---------------- DATASET ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    def __init__(self, file_list, labels, window_size=20, stride=10):\n",
    "        self.file_list = file_list\n",
    "        self.labels = np.array(labels)\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "\n",
    "        self.samples = []\n",
    "        for fi, fpath in enumerate(file_list):\n",
    "            arr = np.load(fpath)\n",
    "            T = arr.shape[0]\n",
    "            for start in range(0, max(1, T - window_size + 1), stride):\n",
    "                self.samples.append((fi, start))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _load(self, idx, start):\n",
    "        arr = np.load(self.file_list[idx]).astype(np.float32)\n",
    "        T, C, H, W, F = arr.shape\n",
    "        arr = arr.reshape(T, C * H * W, F)\n",
    "        arr = (arr - arr.mean()) / (arr.std() + 1e-8)\n",
    "        arr = arr.mean(axis=1)\n",
    "        return arr[start:start+WINDOW_SIZE]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fi, st = self.samples[idx]\n",
    "        seg = self._load(fi, st)\n",
    "        seg = torch.tensor(seg.T, dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[fi], dtype=torch.float32)\n",
    "        return seg, label\n",
    "\n",
    "\n",
    "# ---------------- MODEL ----------------\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, n_features=200):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(n_features, 64, 3, padding=1), nn.ReLU(), nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(128, 128, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]\n",
    "        return self.fc(last).squeeze(1)\n",
    "\n",
    "\n",
    "# ---------------- TRAIN FUNCTION ----------------\n",
    "def train_one_epoch(model, loader, optim, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "# ---------------- EVAL FUNCTION ----------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(DEVICE)\n",
    "            pred = torch.sigmoid(model(x)).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "            labels.extend(y.numpy())\n",
    "\n",
    "    preds = np.array(preds) > 0.5\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return (\n",
    "        accuracy_score(labels, preds),\n",
    "        precision_score(labels, preds),\n",
    "        recall_score(labels, preds),\n",
    "        f1_score(labels, preds)\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # load files\n",
    "    files = sorted([os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith(\".npy\")])\n",
    "    labels = [0 if \"nonseizure\" in f.lower() else 1 for f in files]\n",
    "\n",
    "    print(\"Loaded:\", len(files), \"files\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    fold = 1\n",
    "    for train_idx, test_idx in skf.split(files, labels):\n",
    "        print(f\"\\n----- Fold {fold} -----\")\n",
    "\n",
    "        train_files = [files[i] for i in train_idx]\n",
    "        test_files = [files[i] for i in test_idx]\n",
    "        train_labels = [labels[i] for i in train_idx]\n",
    "        test_labels = [labels[i] for i in test_idx]\n",
    "\n",
    "        train_ds = EEGFileDataset(train_files, train_labels)\n",
    "        test_ds = EEGFileDataset(test_files, test_labels)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "        model = CNN_LSTM().to(DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        for epoch in range(1, EPOCHS+1):\n",
    "            loss = train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
    "            print(f\"Epoch {epoch}/{EPOCHS} - Loss: {loss:.4f}\")\n",
    "\n",
    "        acc, prec, rec, f1 = evaluate(model, test_loader)\n",
    "        print(f\"[Fold {fold}] ACC={acc:.4f}  PREC={prec:.4f}  REC={rec:.4f}  F1={f1:.4f}\")\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "    print(\"\\nTraining complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bf1a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 20:28:12,816] A new study created in memory with name: no-name-58e6076f-bcbc-4d55-9a7d-e976e36c807f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optuna hyperparameter search (this may take time)...\n",
      "Starting Optuna hyperparameter search (28 trials)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:   4%|â–Ž         | 1/28 [03:47<1:42:21, 227.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 20:32:00,352] Trial 0 finished with value: 0.47368421052631576 and parameters: {'f_emb': 12, 'conv_out': 96, 'lstm_hidden': 192, 'lstm_layers': 2, 'dropout': 0.20308477766956903, 'lr': 0.00018559980846490597, 'weight_decay': 5.415244119402535e-07, 'batch_size': 4, 'mixup_alpha': 0.11649165607921677, 'label_smoothing': 0.07342234736668553}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:   7%|â–‹         | 2/28 [06:56<1:28:52, 205.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 20:35:09,799] Trial 1 finished with value: 0.47368421052631576 and parameters: {'f_emb': 24, 'conv_out': 32, 'lstm_hidden': 96, 'lstm_layers': 2, 'dropout': 0.39140800826863986, 'lr': 0.0015635108708133452, 'weight_decay': 1.6536937182824404e-06, 'batch_size': 4, 'mixup_alpha': 0.048815293937911536, 'label_smoothing': 0.05942122921335242}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  11%|â–ˆ         | 3/28 [10:02<1:21:39, 196.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 20:38:14,958] Trial 2 finished with value: 0.47368421052631576 and parameters: {'f_emb': 12, 'conv_out': 64, 'lstm_hidden': 64, 'lstm_layers': 2, 'dropout': 0.38046855875577923, 'lr': 0.00013511829476450826, 'weight_decay': 6.080390190296596e-07, 'batch_size': 8, 'mixup_alpha': 0.10853961270955836, 'label_smoothing': 0.09944850109823151}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  14%|â–ˆâ–        | 4/28 [14:26<1:29:09, 222.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 20:42:39,098] Trial 3 finished with value: 0.47368421052631576 and parameters: {'f_emb': 16, 'conv_out': 64, 'lstm_hidden': 128, 'lstm_layers': 2, 'dropout': 0.34281758667148643, 'lr': 0.00012863908101989929, 'weight_decay': 2.7155819552829384e-06, 'batch_size': 4, 'mixup_alpha': 0.13235920994105968, 'label_smoothing': 0.007627002034322836}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  18%|â–ˆâ–Š        | 5/28 [19:39<1:37:56, 255.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 20:47:52,444] Trial 4 finished with value: 0.47368421052631576 and parameters: {'f_emb': 16, 'conv_out': 32, 'lstm_hidden': 128, 'lstm_layers': 2, 'dropout': 0.2568852545896374, 'lr': 0.00010903028125371, 'weight_decay': 2.701255772543906e-07, 'batch_size': 4, 'mixup_alpha': 0.20342827646588113, 'label_smoothing': 0.10890797687113116}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  21%|â–ˆâ–ˆâ–       | 6/28 [24:16<1:36:19, 262.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 20:52:29,102] Trial 5 finished with value: 0.47368421052631576 and parameters: {'f_emb': 16, 'conv_out': 96, 'lstm_hidden': 128, 'lstm_layers': 1, 'dropout': 0.3731397496224944, 'lr': 0.0006261435181296009, 'weight_decay': 0.0001697307853246701, 'batch_size': 2, 'mixup_alpha': 0.09117406501677668, 'label_smoothing': 0.05125293463515076}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  25%|â–ˆâ–ˆâ–Œ       | 7/28 [27:18<1:22:44, 236.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 20:55:31,321] Trial 6 finished with value: 0.47368421052631576 and parameters: {'f_emb': 12, 'conv_out': 32, 'lstm_hidden': 64, 'lstm_layers': 1, 'dropout': 0.39294552068024013, 'lr': 0.0026402883285404338, 'weight_decay': 1.0165510266418728e-06, 'batch_size': 2, 'mixup_alpha': 0.014754778941813118, 'label_smoothing': 0.07314772007758762}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  29%|â–ˆâ–ˆâ–Š       | 8/28 [30:33<1:14:23, 223.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 20:58:46,114] Trial 7 finished with value: 0.47368421052631576 and parameters: {'f_emb': 24, 'conv_out': 96, 'lstm_hidden': 128, 'lstm_layers': 2, 'dropout': 0.2419457831798133, 'lr': 0.0008589984533104169, 'weight_decay': 3.420730367009223e-05, 'batch_size': 8, 'mixup_alpha': 0.12831202598869434, 'label_smoothing': 0.022382221247982507}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  32%|â–ˆâ–ˆâ–ˆâ–      | 9/28 [33:59<1:08:59, 217.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 21:02:12,348] Trial 8 finished with value: 0.47368421052631576 and parameters: {'f_emb': 16, 'conv_out': 64, 'lstm_hidden': 128, 'lstm_layers': 1, 'dropout': 0.17836838031014726, 'lr': 0.002322119672134761, 'weight_decay': 0.0003231152185441096, 'batch_size': 8, 'mixup_alpha': 0.22208032463978494, 'label_smoothing': 0.06355806940272078}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 10/28 [36:43<1:00:24, 201.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 21:04:56,685] Trial 9 finished with value: 0.47368421052631576 and parameters: {'f_emb': 24, 'conv_out': 96, 'lstm_hidden': 64, 'lstm_layers': 1, 'dropout': 0.19040717852365344, 'lr': 0.002124581964224018, 'weight_decay': 2.6651167490553527e-05, 'batch_size': 8, 'mixup_alpha': 0.0020246335384874747, 'label_smoothing': 0.01929696617009984}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 11/28 [39:39<54:48, 193.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 21:07:52,124] Trial 10 finished with value: 0.47368421052631576 and parameters: {'f_emb': 8, 'conv_out': 48, 'lstm_hidden': 192, 'lstm_layers': 2, 'dropout': 0.3014340217096559, 'lr': 0.0002779525665364969, 'weight_decay': 1.154460820484615e-07, 'batch_size': 4, 'mixup_alpha': 0.35246815990762714, 'label_smoothing': 0.08860866536700247}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 12/28 [42:34<50:07, 187.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 21:10:47,659] Trial 11 finished with value: 0.47368421052631576 and parameters: {'f_emb': 24, 'conv_out': 32, 'lstm_hidden': 96, 'lstm_layers': 2, 'dropout': 0.21556784470333845, 'lr': 0.0011759017643385166, 'weight_decay': 3.989351689203591e-06, 'batch_size': 4, 'mixup_alpha': 0.05847652670971409, 'label_smoothing': 0.043866116914031805}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 13/28 [45:36<46:31, 186.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 21:13:49,463] Trial 12 finished with value: 0.47368421052631576 and parameters: {'f_emb': 12, 'conv_out': 48, 'lstm_hidden': 192, 'lstm_layers': 2, 'dropout': 0.3069107363139875, 'lr': 0.00035923108559161203, 'weight_decay': 1.888349475670485e-06, 'batch_size': 4, 'mixup_alpha': 0.26040632126863783, 'label_smoothing': 0.07930268703507437}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 14/28 [49:04<44:59, 192.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 21:17:17,744] Trial 13 finished with value: 0.47368421052631576 and parameters: {'f_emb': 8, 'conv_out': 96, 'lstm_hidden': 96, 'lstm_layers': 2, 'dropout': 0.16375989367392613, 'lr': 0.00026837612844284953, 'weight_decay': 8.096890290594432e-06, 'batch_size': 4, 'mixup_alpha': 0.05552513502103515, 'label_smoothing': 0.043289042545294996}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 15/28 [52:46<43:38, 201.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-01 21:20:59,267] Trial 14 finished with value: 0.47368421052631576 and parameters: {'f_emb': 12, 'conv_out': 32, 'lstm_hidden': 192, 'lstm_layers': 2, 'dropout': 0.29059691805955107, 'lr': 0.001318220983628871, 'weight_decay': 3.3128696934532074e-07, 'batch_size': 4, 'mixup_alpha': 0.15530826982690532, 'label_smoothing': 0.062385976406007404}. Best is trial 0 with value: 0.47368421052631576.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.473684:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 15/28 [54:13<46:59, 216.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-01 21:22:26,101] Trial 15 failed with parameters: {'f_emb': 24, 'conv_out': 96, 'lstm_hidden': 96, 'lstm_layers': 2, 'dropout': 0.33768196107475296, 'lr': 0.0004781229797987129, 'weight_decay': 1.0145879783310017e-07, 'batch_size': 4, 'mixup_alpha': 0.288587996546179, 'label_smoothing': 0.09011966832150309} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\91730\\AppData\\Local\\Temp\\ipykernel_2088\\848282539.py\", line 413, in objective\n",
      "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\91730\\AppData\\Local\\Temp\\ipykernel_2088\\848282539.py\", line 340, in train_one_epoch\n",
      "    nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
      "  File \"c:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 43, in _no_grad_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 232, in clip_grad_norm_\n",
      "    _clip_grads_with_norm_(parameters, max_norm, total_norm, foreach)\n",
      "  File \"c:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 43, in _no_grad_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 174, in _clip_grads_with_norm_\n",
      "    torch._foreach_mul_(device_grads, clip_coef_clamped.to(device))\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-01 21:22:26,155] Trial 15 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 542\u001b[39m\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDATA_DIR \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist. Create dataset folders first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    541\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Optuna hyperparameter search (this may take time)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m \u001b[43mrun_optuna_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 505\u001b[39m, in \u001b[36mrun_optuna_and_train\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    503\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, sampler=sampler, pruner=pruner)\n\u001b[32m    504\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting Optuna hyperparameter search (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTRIALS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trials)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRIALS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m== Optuna best trial ==\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    508\u001b[39m best = study.best_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 413\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    411\u001b[39m patience = \u001b[32m0\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, TRIAL_EPOCHS + \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     train_loss, train_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixup_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmixup_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m     scheduler.step()\n\u001b[32m    416\u001b[39m     val_loss, val_acc, val_f1, _, _, _ = evaluate(model, val_loader, criterion, DEVICE, label_smoothing=label_smoothing)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 340\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device, mixup_alpha, label_smoothing)\u001b[39m\n\u001b[32m    337\u001b[39m     loss = criterion(logits, y_s)\n\u001b[32m    339\u001b[39m loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m optimizer.step()\n\u001b[32m    343\u001b[39m losses.append(loss.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:43\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:232\u001b[39m, in \u001b[36mclip_grad_norm_\u001b[39m\u001b[34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m    230\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    231\u001b[39m total_norm = _get_total_norm(grads, norm_type, error_if_nonfinite, foreach)\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[43m_clip_grads_with_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:43\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:174\u001b[39m, in \u001b[36m_clip_grads_with_norm_\u001b[39m\u001b[34m(parameters, max_norm, total_norm, foreach)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([device_grads], _) \u001b[38;5;129;01min\u001b[39;00m grouped_grads.items():\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(device_grads, device)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    172\u001b[39m         foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)\n\u001b[32m    173\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_coef_clamped\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    177\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mforeach=True was passed, but can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice.type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m         )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# improved_eeg_cnn_lstm_optuna_fixed.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- CONFIG (change as needed) ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"   # expects subfolders 'healthy' and 'patient'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "GLOBAL_SEED = 42\n",
    "\n",
    "NUM_FOLDS_FINAL = 5     # final cross-validation folds after tuning\n",
    "TRIALS = 28             # optuna trials (adjust)\n",
    "TRIAL_EPOCHS = 16       # epochs per trial (kept small for speed)\n",
    "FINAL_EPOCHS = 60       # epochs for final training per fold\n",
    "EARLY_STOP_PATIENCE = 12\n",
    "\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# stable seeds\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "random.seed(GLOBAL_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(GLOBAL_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads .npy files: expected shape (T, C, H, W, F)\n",
    "    If files+labels provided, uses them; otherwise discovers healthy/patient folders.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir=None, folders=(\"healthy\", \"patient\"),\n",
    "                 files=None, labels=None, augment=False, aug_factor=1):\n",
    "        self.augment = bool(augment)\n",
    "        self.aug_factor = int(aug_factor)\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "\n",
    "        if files is not None and labels is not None:\n",
    "            if len(files) != len(labels):\n",
    "                raise ValueError(\"files and labels must be same length\")\n",
    "            self.files = list(files)\n",
    "            self.labels = np.array(labels, dtype=np.int64)\n",
    "        else:\n",
    "            if data_dir is None:\n",
    "                raise ValueError(\"Either data_dir or files+labels must be provided\")\n",
    "            for label, folder in enumerate(folders):\n",
    "                folder_path = os.path.join(data_dir, folder)\n",
    "                if not os.path.isdir(folder_path):\n",
    "                    raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "                for fname in os.listdir(folder_path):\n",
    "                    if fname.endswith(\".npy\"):\n",
    "                        self.files.append(os.path.join(folder_path, fname))\n",
    "                        self.labels.append(label)\n",
    "            if len(self.files) == 0:\n",
    "                raise RuntimeError(\"No .npy files found in dataset folders\")\n",
    "            # stable ordering\n",
    "            idxs = np.argsort(self.files)\n",
    "            self.files = [self.files[i] for i in idxs]\n",
    "            self.labels = np.array([self.labels[i] for i in idxs], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files) * (self.aug_factor if self.augment else 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = idx % len(self.files)\n",
    "        arr = np.load(self.files[real_idx])  # expected (T,C,H,W,F)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[real_idx]} shape {arr.shape} != (T,C,H,W,F)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "\n",
    "        # sample-level normalization\n",
    "        mean = arr.mean()\n",
    "        std = arr.std() + 1e-8\n",
    "        arr = (arr - mean) / std\n",
    "\n",
    "        if self.augment:\n",
    "            # noise\n",
    "            if np.random.rand() < 0.5:\n",
    "                noise_std = np.random.uniform(0.005, 0.035)\n",
    "                arr += np.random.normal(0, noise_std, arr.shape).astype(np.float32)\n",
    "            # amplitude scaling\n",
    "            if np.random.rand() < 0.4:\n",
    "                scale = np.random.uniform(0.92, 1.08)\n",
    "                arr *= scale\n",
    "            # time shift small\n",
    "            if np.random.rand() < 0.4:\n",
    "                shift = np.random.randint(-4, 5)\n",
    "                arr = np.roll(arr, shift, axis=0)\n",
    "            # frequency masking\n",
    "            if np.random.rand() < 0.35:\n",
    "                F = arr.shape[-1]\n",
    "                mask_len = np.random.randint(6, max(6, min(40, F//3)))\n",
    "                start = np.random.randint(0, max(1, F-mask_len))\n",
    "                arr[..., start:start+mask_len] *= np.random.uniform(0.02, 0.6)\n",
    "\n",
    "        label = int(self.labels[real_idx])\n",
    "        return torch.from_numpy(arr), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# ---------------- Utilities ----------------\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.drop_prob == 0.0:\n",
    "            return x\n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "        random_tensor = torch.floor(random_tensor)\n",
    "        return x / keep_prob * random_tensor\n",
    "\n",
    "class CNN_LSTM_Attention(nn.Module):\n",
    "    def __init__(self, in_freq=200, f_emb=16, conv_out=64,\n",
    "                 H=5, W=5, C=8, lstm_hidden=128, lstm_layers=1,\n",
    "                 dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.in_freq = in_freq\n",
    "        self.f_emb = f_emb\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "\n",
    "        # freq embedding\n",
    "        self.freq_emb = nn.Sequential(\n",
    "            nn.Linear(in_freq, f_emb),\n",
    "            nn.LayerNorm(f_emb),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        in_ch = C * f_emb\n",
    "        self.spatial_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, conv_out, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(conv_out),\n",
    "            nn.GELU(),\n",
    "            DropPath(0.08),\n",
    "\n",
    "            nn.Conv2d(conv_out, conv_out, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(conv_out),\n",
    "            nn.GELU(),\n",
    "            DropPath(0.08),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        feat_dim = conv_out\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=feat_dim,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0\n",
    "        )\n",
    "        self.lstm_norm = nn.LayerNorm(lstm_hidden * 2)\n",
    "        self.lstm_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        att_dim = lstm_hidden * 2\n",
    "        self.att_q = nn.Linear(att_dim, att_dim)\n",
    "        self.att_k = nn.Linear(att_dim, att_dim)\n",
    "        self.att_v = nn.Linear(att_dim, att_dim)\n",
    "        self.att_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # classifier expects concatenated max+mean = att_dim*2\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(att_dim * 2, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(128, 32),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for n, p in self.named_parameters():\n",
    "            if p.dim() > 1:\n",
    "                try:\n",
    "                    nn.init.kaiming_normal_(p)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, T, C, H, W, F)\n",
    "        returns logits (B,)\n",
    "        \"\"\"\n",
    "        B, T, C, H, W, F = x.shape\n",
    "        assert C == self.C and H == self.H and W == self.W and F == self.in_freq, \\\n",
    "            f\"Model configured for (C,H,W,F)=({self.C},{self.H},{self.W},{self.in_freq}) but got {(C,H,W,F)}\"\n",
    "\n",
    "        # (B*T*C*H*W, F)\n",
    "        x_flat = x.view(B * T * C * H * W, F)\n",
    "        x_femb = self.freq_emb(x_flat)  # (B*T*C*H*W, f_emb)\n",
    "        x_femb = x_femb.view(B, T, C, H, W, self.f_emb)\n",
    "\n",
    "        # -> (B*T, C*f_emb, H, W)\n",
    "        x_per_time = x_femb.permute(0,1,2,5,3,4).contiguous()\n",
    "        x_per_time = x_per_time.view(B * T, C * self.f_emb, H, W)\n",
    "\n",
    "        conv_out = self.spatial_conv(x_per_time)  # (B*T, conv_out,1,1)\n",
    "        conv_out = conv_out.view(B, T, -1)        # (B, T, conv_out)\n",
    "\n",
    "        lstm_out, _ = self.lstm(conv_out)         # (B, T, att_dim)\n",
    "        lstm_out = self.lstm_norm(lstm_out)\n",
    "        lstm_out = self.lstm_dropout(lstm_out)\n",
    "\n",
    "        Q = self.att_q(lstm_out)\n",
    "        K = self.att_k(lstm_out)\n",
    "        V = self.att_v(lstm_out)\n",
    "        d = Q.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (d ** 0.5)\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        weights = self.att_dropout(weights)\n",
    "        attended = torch.matmul(weights, V)       # (B, T, d)\n",
    "\n",
    "        max_pool = torch.max(attended, dim=1)[0]\n",
    "        mean_pool = torch.mean(attended, dim=1)\n",
    "        combined = torch.cat([max_pool, mean_pool], dim=1)  # (B, d*2)\n",
    "\n",
    "        logits = self.classifier(combined).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Losses ----------------\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # targets: float (0..1) allowed for label smoothing/mixup\n",
    "        bce = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=self.pos_weight, reduction='none'\n",
    "        )\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt = torch.where(targets == 1, probs, 1 - probs)\n",
    "        focal = (1 - pt) ** self.gamma\n",
    "        alpha_w = torch.where(targets == 1, self.alpha, 1 - self.alpha)\n",
    "        loss = alpha_w * focal * bce\n",
    "        return loss.mean()\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha <= 0:\n",
    "        return x, y, None, 1.0\n",
    "    lam = float(np.random.beta(alpha, alpha))\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size, device=x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# ---------------- Data loader prep (kfold) ----------------\n",
    "def prepare_loaders_kfold(data_dir, fold_idx=0, num_folds=5, aug_factor=3,\n",
    "                          batch_size=4, num_workers=0):\n",
    "    full_ds = EEGFileDataset(data_dir=data_dir, augment=False, aug_factor=1)\n",
    "    n = len(full_ds)\n",
    "    indices = np.arange(n)\n",
    "    # extract labels by calling dataset __getitem__ item  -> returns (tensor,label)\n",
    "    labels = np.array([int(full_ds[i][1].item()) for i in range(n)])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=GLOBAL_SEED)\n",
    "    splits = list(skf.split(indices, labels))\n",
    "    train_idx, val_idx = splits[fold_idx]\n",
    "\n",
    "    train_files = [full_ds.files[i] for i in train_idx]\n",
    "    train_labels = [int(full_ds.labels[i]) for i in train_idx]\n",
    "    val_files = [full_ds.files[i] for i in val_idx]\n",
    "    val_labels = [int(full_ds.labels[i]) for i in val_idx]\n",
    "\n",
    "    train_ds = EEGFileDataset(files=train_files, labels=train_labels, augment=True, aug_factor=aug_factor)\n",
    "    val_ds = EEGFileDataset(files=val_files, labels=val_labels, augment=False, aug_factor=1)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    neg = sum([1 for l in train_labels if l == 0])\n",
    "    pos = sum([1 for l in train_labels if l == 1])\n",
    "    pos_weight = torch.tensor([ (neg / (pos + 1e-12)) ], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Training per fold ----------------\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, mixup_alpha=0.2, label_smoothing=0.0):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for X, y in loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if X.size(0) > 1 and np.random.rand() < 0.6 and mixup_alpha > 0.0:\n",
    "            X_m, ya, yb, lam = mixup_data(X, y, mixup_alpha)\n",
    "            logits = model(X_m)\n",
    "            ya_s = ya.float() * (1 - label_smoothing) + 0.5 * label_smoothing\n",
    "            yb_s = yb.float() * (1 - label_smoothing) + 0.5 * label_smoothing\n",
    "            loss = lam * criterion(logits, ya_s) + (1 - lam) * criterion(logits, yb_s)\n",
    "        else:\n",
    "            logits = model(X)\n",
    "            y_s = y * (1 - label_smoothing) + 0.5 * label_smoothing\n",
    "            loss = criterion(logits, y_s)\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "        trues.extend(y.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    avg_loss = float(np.mean(losses)) if losses else 0.0\n",
    "    acc = accuracy_score(trues, preds) if len(trues) else 0.0\n",
    "    return avg_loss, acc\n",
    "\n",
    "def evaluate(model, loader, criterion, device, label_smoothing=0.0):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    preds = []\n",
    "    trues = []\n",
    "    probs_all = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device).float()\n",
    "            y_s = y * (1 - label_smoothing) + 0.5 * label_smoothing\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y_s)\n",
    "            losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            probs_all.extend(probs.tolist())\n",
    "            preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            trues.extend(y.cpu().numpy().astype(int).tolist())\n",
    "    avg_loss = float(np.mean(losses)) if losses else 0.0\n",
    "    acc = accuracy_score(trues, preds) if len(trues) else 0.0\n",
    "    f1 = f1_score(trues, preds, zero_division=0) if len(trues) else 0.0\n",
    "    return avg_loss, acc, f1, probs_all, trues, preds\n",
    "\n",
    "# ---------------- Optuna objective ----------------\n",
    "def objective(trial):\n",
    "    # hyperparams to search\n",
    "    f_emb = trial.suggest_categorical(\"f_emb\", [8, 12, 16, 24])\n",
    "    conv_out = trial.suggest_categorical(\"conv_out\", [32, 48, 64, 96])\n",
    "    lstm_hidden = trial.suggest_categorical(\"lstm_hidden\", [64, 96, 128, 192])\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 2)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.15, 0.4)\n",
    "    # use modern suggest_float with log=True\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 3e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-7, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [2, 4, 8])\n",
    "    mixup_alpha = trial.suggest_float(\"mixup_alpha\", 0.0, 0.4)\n",
    "    label_smoothing = trial.suggest_float(\"label_smoothing\", 0.0, 0.12)\n",
    "\n",
    "    # prepare loaders on fold 0 for speed\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders_kfold(\n",
    "        DATA_DIR, fold_idx=0, num_folds=NUM_FOLDS_FINAL,\n",
    "        aug_factor=3, batch_size=batch_size, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    # infer dims\n",
    "    sample_X, _ = next(iter(train_loader))\n",
    "    B, T, C, H, W, F = sample_X.shape\n",
    "\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model = CNN_LSTM_Attention(in_freq=F, f_emb=f_emb, conv_out=conv_out,\n",
    "                               H=H, W=W, C=C, lstm_hidden=lstm_hidden,\n",
    "                               lstm_layers=lstm_layers, dropout=dropout).to(DEVICE)\n",
    "\n",
    "    # use focal or bce\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2.0, pos_weight=pos_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=8, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience = 0\n",
    "    for epoch in range(1, TRIAL_EPOCHS + 1):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion,\n",
    "                                                DEVICE, mixup_alpha=mixup_alpha, label_smoothing=label_smoothing)\n",
    "        scheduler.step()\n",
    "        val_loss, val_acc, val_f1, _, _, _ = evaluate(model, val_loader, criterion, DEVICE, label_smoothing=label_smoothing)\n",
    "\n",
    "        trial.report(val_acc, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience = 0\n",
    "            # save the best model for this trial\n",
    "            torch.save({'model_state': model.state_dict(), 'params': trial.params}, \"optuna_trial_best_temp.pth\")\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        # early stopping for trial to save time\n",
    "        if patience >= 6:\n",
    "            break\n",
    "\n",
    "    return best_val_acc\n",
    "\n",
    "# ---------------- Final training and evaluation (k-fold) ----------------\n",
    "def train_fold_with_params(fold_idx, params, epochs=FINAL_EPOCHS):\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders_kfold(\n",
    "        DATA_DIR, fold_idx=fold_idx, num_folds=NUM_FOLDS_FINAL,\n",
    "        aug_factor=3, batch_size=params['batch_size'], num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    sample_X, _ = next(iter(train_loader))\n",
    "    B, T, C, H, W, F = sample_X.shape\n",
    "\n",
    "    set_seed(GLOBAL_SEED + fold_idx)\n",
    "    model = CNN_LSTM_Attention(in_freq=F, f_emb=params['f_emb'], conv_out=params['conv_out'],\n",
    "                               H=H, W=W, C=C, lstm_hidden=params['lstm_hidden'],\n",
    "                               lstm_layers=params['lstm_layers'], dropout=params['dropout']).to(DEVICE)\n",
    "\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2.0, pos_weight=pos_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience = 0\n",
    "    best_state = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion, DEVICE,\n",
    "            mixup_alpha=params.get('mixup_alpha', 0.0), label_smoothing=params.get('label_smoothing', 0.0)\n",
    "        )\n",
    "        scheduler.step()\n",
    "        val_loss, val_acc, val_f1, val_probs, val_trues, val_preds = evaluate(\n",
    "            model, val_loader, criterion, DEVICE, label_smoothing=params.get('label_smoothing', 0.0)\n",
    "        )\n",
    "\n",
    "        print(f\"Fold {fold_idx+1} Epoch {epoch}/{epochs} | TrainLoss={train_loss:.4f} TrainAcc={train_acc:.4f} | ValLoss={val_loss:.4f} ValAcc={val_acc:.4f} ValF1={val_f1:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience = 0\n",
    "            best_state = {\n",
    "                'model_state': model.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_acc': val_acc\n",
    "            }\n",
    "            torch.save(best_state, f\"best_model_fold{fold_idx}.pth\")\n",
    "            print(\"  -> saved best model\")\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        if patience >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"Early stopping fold {fold_idx+1} at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    # load best and final evaluate\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state['model_state'])\n",
    "    val_loss, val_acc, val_f1, val_probs, val_trues, val_preds = evaluate(\n",
    "        model, val_loader, criterion, DEVICE, label_smoothing=params.get('label_smoothing', 0.0)\n",
    "    )\n",
    "    cm = confusion_matrix(val_trues, val_preds) if len(val_trues) > 0 else None\n",
    "    print(f\"\\n=== Fold {fold_idx+1} Final: Acc={val_acc:.4f} F1={val_f1:.4f} ===\")\n",
    "    if cm is not None:\n",
    "        print(cm)\n",
    "    return val_acc, val_f1\n",
    "\n",
    "def run_optuna_and_train():\n",
    "    sampler = optuna.samplers.TPESampler(seed=GLOBAL_SEED)\n",
    "    pruner = optuna.pruners.MedianPruner(n_startup_trials=4, n_warmup_steps=3)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)\n",
    "    print(f\"Starting Optuna hyperparameter search ({TRIALS} trials)...\")\n",
    "    study.optimize(objective, n_trials=TRIALS, show_progress_bar=True)\n",
    "\n",
    "    print(\"\\n== Optuna best trial ==\")\n",
    "    best = study.best_trial\n",
    "    print(f\"Value: {best.value:.4f}\")\n",
    "    print(\"Params:\")\n",
    "    for k, v in best.params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    # Build final params dictionary\n",
    "    best_params = dict(best.params)\n",
    "    # provide defaults for any missing keys\n",
    "    defaults = {'mixup_alpha': 0.2, 'label_smoothing': 0.02}\n",
    "    for k, v in defaults.items():\n",
    "        best_params.setdefault(k, v)\n",
    "\n",
    "    # After tuning, run K-fold final training\n",
    "    all_accs = []\n",
    "    all_f1s = []\n",
    "    for fold in range(NUM_FOLDS_FINAL):\n",
    "        acc, f1 = train_fold_with_params(fold, best_params, epochs=FINAL_EPOCHS)\n",
    "        all_accs.append(acc)\n",
    "        all_f1s.append(f1)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Final K-Fold Results\")\n",
    "    print(f\"Mean Accuracy: {np.mean(all_accs):.4f} Â± {np.std(all_accs):.4f}\")\n",
    "    print(f\"Mean F1-score: {np.mean(all_f1s):.4f} Â± {np.std(all_f1s):.4f}\")\n",
    "    print(f\"Individual accuracies: {[f'{a:.4f}' for a in all_accs]}\")\n",
    "\n",
    "# ---------------- Entrypoint ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Basic checks\n",
    "    if not os.path.isdir(DATA_DIR):\n",
    "        raise SystemExit(f\"DATA_DIR {DATA_DIR} does not exist. Create dataset folders first.\")\n",
    "\n",
    "    print(\"Starting Optuna hyperparameter search (this may take time)...\")\n",
    "    run_optuna_and_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cee6a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING K-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 Dataset Info ===\n",
      "Train (file-level): 72 (Healthy=32, Patient=40)\n",
      "Val (file-level): 19\n",
      "Pos_weight: 0.800\n",
      "\n",
      "\n",
      "=== Model Info ===\n",
      "Device: cpu\n",
      "Total parameters: 3,929,601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1/200]\n",
      "  Train: Loss=0.0799, Acc=0.4333\n",
      "  Val:   Loss=0.0639, Acc=0.4737, F1=0.0000\n",
      "  Prob range: [0.393, 0.393]\n",
      "  âœ“ Best acc: 0.4737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 10/200]\n",
      "  Train: Loss=0.0652, Acc=0.4417\n",
      "  Val:   Loss=0.0645, Acc=0.4737, F1=0.0000\n",
      "  Prob range: [0.420, 0.420]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 20/200]\n",
      "  Train: Loss=0.0633, Acc=0.4444\n",
      "  Val:   Loss=0.0640, Acc=0.4737, F1=0.0000\n",
      "  Prob range: [0.396, 0.403]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 30/200]\n",
      "  Train: Loss=0.0647, Acc=0.4444\n",
      "  Val:   Loss=0.0639, Acc=0.4737, F1=0.0000\n",
      "  Prob range: [0.394, 0.394]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 40/200]\n",
      "  Train: Loss=0.0646, Acc=0.4444\n",
      "  Val:   Loss=0.0638, Acc=0.4737, F1=0.0000\n",
      "  Prob range: [0.396, 0.398]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping at epoch 41\n",
      "\n",
      "=== Fold 1 Final Results ===\n",
      "Accuracy: 0.4737 (47.37%)\n",
      "F1-score: 0.0000\n",
      "Confusion Matrix:\n",
      "[[ 9  0]\n",
      " [10  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2/5 Dataset Info ===\n",
      "Train (file-level): 73 (Healthy=33, Patient=40)\n",
      "Val (file-level): 18\n",
      "Pos_weight: 0.825\n",
      "\n",
      "\n",
      "=== Model Info ===\n",
      "Device: cpu\n",
      "Total parameters: 3,929,601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1/200]\n",
      "  Train: Loss=0.0851, Acc=0.4247\n",
      "  Val:   Loss=0.0697, Acc=0.4444, F1=0.0000\n",
      "  Prob range: [0.341, 0.342]\n",
      "  âœ“ Best acc: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 10/200]\n",
      "  Train: Loss=0.0657, Acc=0.4521\n",
      "  Val:   Loss=0.0661, Acc=0.4444, F1=0.0000\n",
      "  Prob range: [0.373, 0.373]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 20/200]\n",
      "  Train: Loss=0.0609, Acc=0.6329\n",
      "  Val:   Loss=0.0742, Acc=0.4444, F1=0.2857\n",
      "  Prob range: [0.336, 0.572]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 30/200]\n",
      "  Train: Loss=0.0665, Acc=0.4521\n",
      "  Val:   Loss=0.0654, Acc=0.4444, F1=0.0000\n",
      "  Prob range: [0.418, 0.418]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 502\u001b[39m\n\u001b[32m    499\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâš   Current: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(all_accs)*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% - Try adjusting hyperparameters\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m     \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 484\u001b[39m, in \u001b[36mtrain_and_evaluate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    481\u001b[39m all_f1s = []\n\u001b[32m    483\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_FOLDS):\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     acc, f1, cm, hist = \u001b[43mtrain_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m     all_accs.append(acc)\n\u001b[32m    486\u001b[39m     all_f1s.append(f1)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 360\u001b[39m, in \u001b[36mtrain_fold\u001b[39m\u001b[34m(fold_idx)\u001b[39m\n\u001b[32m    357\u001b[39m     logits = model(X)\n\u001b[32m    358\u001b[39m     loss = criterion(logits, y)\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n\u001b[32m    362\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91730\\Desktop\\Final Year Project\\Updated Model\\myenv\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_DIR = r\"processed_lstm_inputs\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 2  # Very small batch for tiny dataset\n",
    "EPOCHS = 200\n",
    "LR = 5e-4  # Slightly higher to help learning\n",
    "VAL_SPLIT = 0.2\n",
    "LSTM_HIDDEN = 256\n",
    "LSTM_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "GRAD_CLIP = 1.0\n",
    "NUM_WORKERS = 0\n",
    "EARLY_STOP_PATIENCE = 40\n",
    "NUM_FOLDS = 5  # K-fold cross-validation\n",
    "AUG_FACTOR = 5  # how many augmented copies per file for training\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ---------------- Dataset ----------------\n",
    "class EEGFileDataset(Dataset):\n",
    "    def __init__(self, data_dir, folders=(\"healthy\",\"patient\"), augment=False, aug_factor=1):\n",
    "        self.augment = augment\n",
    "        self.aug_factor = max(1, int(aug_factor))\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        for label, folder in enumerate(folders):\n",
    "            folder_path = os.path.join(data_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                raise FileNotFoundError(f\"{folder_path} not found\")\n",
    "            for fname in sorted(os.listdir(folder_path)):\n",
    "                if fname.endswith(\".npy\"):\n",
    "                    self.files.append(os.path.join(folder_path, fname))\n",
    "                    self.labels.append(label)\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No .npy files found.\")\n",
    "        self.labels = np.array(self.labels, dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files) * self.aug_factor if self.augment else len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = idx % len(self.files)\n",
    "        arr = np.load(self.files[real_idx])  # expected shape (44,8,5,5,200)\n",
    "        if arr.ndim != 5:\n",
    "            raise ValueError(f\"{self.files[real_idx]} shape {arr.shape} != (44,8,5,5,200)\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        T, C, H, W, F = arr.shape\n",
    "\n",
    "        # Combine spatial channels then normalize per-frequency across time\n",
    "        arr = arr.reshape(T, C*H*W, F)  # (T, spatial, F)\n",
    "        mean = arr.mean(axis=(0, 2), keepdims=True)\n",
    "        std = arr.std(axis=(0, 2), keepdims=True) + 1e-8\n",
    "        arr = (arr - mean) / std\n",
    "        arr = arr.mean(axis=1)  # (T, F)\n",
    "\n",
    "        # Augmentation (applied when dataset was created with augment=True)\n",
    "        if self.augment:\n",
    "            # Random noise\n",
    "            if np.random.rand() > 0.3:\n",
    "                noise_std = np.random.uniform(0.02, 0.05)\n",
    "                arr += np.random.normal(0, noise_std, arr.shape).astype(np.float32)\n",
    "            # Random amplitude scaling\n",
    "            if np.random.rand() > 0.3:\n",
    "                scale = np.random.uniform(0.85, 1.15)\n",
    "                arr *= scale\n",
    "            # Time shift\n",
    "            if np.random.rand() > 0.5:\n",
    "                shift = np.random.randint(-5, 6)\n",
    "                arr = np.roll(arr, shift, axis=0)\n",
    "            # Time warping (simple resample)\n",
    "            if np.random.rand() > 0.6:\n",
    "                warp_factor = np.random.uniform(0.9, 1.1)\n",
    "                new_len = max(1, int(T * warp_factor))\n",
    "                indices = np.linspace(0, T-1, new_len)\n",
    "                arr_warped = np.zeros((new_len, F), dtype=np.float32)\n",
    "                for i in range(new_len):\n",
    "                    idx_i = int(indices[i])\n",
    "                    arr_warped[i] = arr[idx_i]\n",
    "                if new_len > T:\n",
    "                    arr = arr_warped[:T]\n",
    "                else:\n",
    "                    arr = np.pad(arr_warped, ((0, T-new_len), (0, 0)), mode='edge')\n",
    "            # Frequency masking\n",
    "            if np.random.rand() > 0.5:\n",
    "                mask_len = np.random.randint(10, min(30, F))\n",
    "                mask_start = np.random.randint(0, max(1, F - mask_len))\n",
    "                arr[:, mask_start:mask_start+mask_len] *= np.random.uniform(0.1, 0.3)\n",
    "\n",
    "        # Return (T, F) as torch tensor\n",
    "        return torch.from_numpy(arr), torch.tensor(self.labels[real_idx], dtype=torch.long)\n",
    "\n",
    "# ---------------- CNN Feature Extractor with Attention ----------------\n",
    "class ChannelSpatialCNN(nn.Module):\n",
    "    def __init__(self, in_features=200, hidden_channels=64, dropout=0.2):\n",
    "        super().__init__()\n",
    "        # We'll treat features as 1D signal per time-step and apply convs across the feature axis.\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=hidden_channels, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=hidden_channels, out_channels=hidden_channels*2, kernel_size=3, padding=1)\n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # attention across channels\n",
    "        self.attn_proj = nn.Sequential(\n",
    "            nn.Conv1d(hidden_channels*2, hidden_channels*2, kernel_size=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(hidden_channels*2, hidden_channels*2, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.out_dim = hidden_channels*2\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq, features)\n",
    "        b, s, f = x.shape\n",
    "        x = x.contiguous().view(b*s, 1, f)            # (b*s, 1, f)\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)                          # (b*s, out_ch, f)\n",
    "\n",
    "        att = self.attn_proj(x)                      # (b*s, out_ch, f)\n",
    "        x = x * att\n",
    "\n",
    "        # Pool across feature axis to get a vector per time-step\n",
    "        x = x.mean(dim=2)                            # (b*s, out_ch)\n",
    "        x = x.view(b, s, -1)                         # (b, seq, out_ch)\n",
    "        return x\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class DeepLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=200, hidden_size=LSTM_HIDDEN, num_layers=LSTM_LAYERS, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        # CNN front-end\n",
    "        self.cnn = ChannelSpatialCNN(in_features=input_size, hidden_channels=64, dropout=dropout)\n",
    "        cnn_out = self.cnn.out_dim  # feature dim per time-step after cnn\n",
    "\n",
    "        # small MLP per time-step\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(cnn_out, cnn_out),\n",
    "            nn.LayerNorm(cnn_out),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.3)\n",
    "        )\n",
    "\n",
    "        # Bidirectional LSTM over time dimension (T)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=cnn_out,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers>1 else 0.0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        lstm_output_size = hidden_size * 2\n",
    "\n",
    "        # Attention (scaled dot product style) projection layers\n",
    "        self.attention_query = nn.Linear(lstm_output_size, lstm_output_size)\n",
    "        self.attention_key = nn.Linear(lstm_output_size, lstm_output_size)\n",
    "        self.attention_value = nn.Linear(lstm_output_size, lstm_output_size)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_size * 2, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.8),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.6),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.4),\n",
    "\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif param.dim() >= 2:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq=T, features=F)\n",
    "        x = self.cnn(x)                 # (batch, seq, cnn_out)\n",
    "        x = self.feature_extractor(x)   # (batch, seq, cnn_out)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)      # (batch, seq, hidden*2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        Q = self.attention_query(lstm_out)\n",
    "        K = self.attention_key(lstm_out)\n",
    "        V = self.attention_value(lstm_out)\n",
    "\n",
    "        d_k = lstm_out.size(-1)\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / (d_k ** 0.5)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "        attended = torch.matmul(attention_weights, V)  # (batch, seq, hidden*2)\n",
    "\n",
    "        # Multi-scale pooling\n",
    "        max_pool = torch.max(attended, dim=1)[0]\n",
    "        mean_pool = torch.mean(attended, dim=1)\n",
    "        combined = torch.cat([max_pool, mean_pool], dim=1)\n",
    "\n",
    "        logits = self.classifier(combined).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "# ---------------- Mixup augmentation ----------------\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ---------------- Loss ----------------\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # logits: (batch,)\n",
    "        targets = targets.float()\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=self.pos_weight, reduction='none'\n",
    "        )\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt = torch.where(targets == 1, probs, 1 - probs)\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "        alpha_weight = torch.where(targets == 1, self.alpha, 1 - self.alpha)\n",
    "        loss = alpha_weight * focal_weight * bce_loss\n",
    "        return loss.mean()\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def prepare_loaders_kfold(data_dir, fold_idx=0, aug_factor=AUG_FACTOR):\n",
    "    full_ds = EEGFileDataset(data_dir, augment=False, aug_factor=1)\n",
    "    n_files = len(full_ds)\n",
    "    indices = np.arange(n_files)\n",
    "    labels = np.array([full_ds[i][1].item() for i in range(n_files)])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "    splits = list(skf.split(indices, labels))\n",
    "    train_files_idx, val_files_idx = splits[fold_idx]\n",
    "\n",
    "    # Create augmented training dataset (we will select indices so each train file appears aug_factor times)\n",
    "    train_ds_aug = EEGFileDataset(data_dir, augment=True, aug_factor=aug_factor)\n",
    "    # build indices into the augmented dataset such that each file in train_files_idx is repeated aug_factor times\n",
    "    augmented_indices = []\n",
    "    for fidx in train_files_idx:\n",
    "        for k in range(aug_factor):\n",
    "            augmented_indices.append(fidx + k * n_files)\n",
    "\n",
    "    train_ds = torch.utils.data.Subset(train_ds_aug, augmented_indices)\n",
    "    val_ds = torch.utils.data.Subset(full_ds, val_files_idx)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "        num_workers=NUM_WORKERS, drop_last=False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    train_labels = labels[train_files_idx]\n",
    "    neg = int((train_labels == 0).sum())\n",
    "    pos = int((train_labels == 1).sum())\n",
    "    pos_weight = torch.tensor([neg / (pos + 1e-12)], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "    print(f\"\\n=== Fold {fold_idx+1}/{NUM_FOLDS} Dataset Info ===\")\n",
    "    print(f\"Train (file-level): {len(train_files_idx)} (Healthy={neg}, Patient={pos})\")\n",
    "    print(f\"Val (file-level): {len(val_files_idx)}\")\n",
    "    print(f\"Pos_weight: {pos_weight.item():.3f}\\n\")\n",
    "\n",
    "    return train_loader, val_loader, pos_weight\n",
    "\n",
    "# ---------------- Train & Evaluate ----------------\n",
    "def train_fold(fold_idx=0):\n",
    "    train_loader, val_loader, pos_weight = prepare_loaders_kfold(DATA_DIR, fold_idx)\n",
    "    model = DeepLSTMModel().to(DEVICE)\n",
    "\n",
    "    print(f\"\\n=== Model Info ===\")\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2.0, pos_weight=pos_weight)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=5e-5)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=20, T_mult=2, eta_min=1e-7\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    history = {\"train_acc\": [], \"val_acc\": [], \"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_trues = [], []\n",
    "\n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False):\n",
    "            X = X.to(DEVICE)\n",
    "            y = y.to(DEVICE).float()\n",
    "\n",
    "            # Apply mixup sometimes\n",
    "            if np.random.rand() > 0.5 and X.size(0) > 1:\n",
    "                X_mixed, y_a, y_b, lam = mixup_data(X, y, alpha=0.2)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(X_mixed)\n",
    "                loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(X)\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            train_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            train_trues.extend(y.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_trues = [], []\n",
    "        val_probs_all = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for Xv, yv in val_loader:\n",
    "                Xv = Xv.to(DEVICE)\n",
    "                yv = yv.to(DEVICE).float()\n",
    "                logits = model(Xv)\n",
    "                loss = criterion(logits, yv)\n",
    "                val_losses.append(loss.item())\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                val_probs_all.extend(probs.tolist())\n",
    "                val_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "                val_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "        avg_train = float(np.mean(train_losses)) if len(train_losses)>0 else 0.0\n",
    "        avg_val = float(np.mean(val_losses)) if len(val_losses)>0 else 0.0\n",
    "        train_acc = accuracy_score(train_trues, train_preds) if len(train_trues)>0 else 0.0\n",
    "        val_acc = accuracy_score(val_trues, val_preds) if len(val_trues)>0 else 0.0\n",
    "        val_f1 = f1_score(val_trues, val_preds, zero_division=0)\n",
    "\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"train_loss\"].append(avg_train)\n",
    "        history[\"val_loss\"].append(avg_val)\n",
    "\n",
    "        if epoch % 10 == 0 or val_acc > best_val_acc:\n",
    "            print(f\"\\n[Epoch {epoch}/{EPOCHS}]\")\n",
    "            print(f\"  Train: Loss={avg_train:.4f}, Acc={train_acc:.4f}\")\n",
    "            print(f\"  Val:   Loss={avg_val:.4f}, Acc={val_acc:.4f}, F1={val_f1:.4f}\")\n",
    "            if len(val_probs_all)>0:\n",
    "                print(f\"  Prob range: [{min(val_probs_all):.3f}, {max(val_probs_all):.3f}]\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "            }, f\"best_model_fold{fold_idx}.pth\")\n",
    "            print(f\"  âœ“ Best acc: {best_val_acc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    # Load best and evaluate\n",
    "    checkpoint = torch.load(f\"best_model_fold{fold_idx}.pth\", map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    all_preds, all_trues = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            Xv = Xv.to(DEVICE)\n",
    "            logits = model(Xv)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_preds.extend((probs >= 0.5).astype(int).tolist())\n",
    "            all_trues.extend(yv.cpu().numpy().astype(int).tolist())\n",
    "\n",
    "    acc = accuracy_score(all_trues, all_preds) if len(all_trues)>0 else 0.0\n",
    "    f1 = f1_score(all_trues, all_preds, zero_division=0)\n",
    "    cm = confusion_matrix(all_trues, all_preds) if len(all_trues)>0 else np.zeros((2,2), dtype=int)\n",
    "\n",
    "    print(f\"\\n=== Fold {fold_idx+1} Final Results ===\")\n",
    "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "    return acc, f1, cm, history\n",
    "\n",
    "# ---------------- Plotting ----------------\n",
    "def plot_learning_curves(history, fold):\n",
    "    epochs = range(1, len(history[\"train_acc\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.title(f\"Accuracy Curve - Fold {fold}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.title(f\"Loss Curve - Fold {fold}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---------------- Train & CV ----------------\n",
    "def train_and_evaluate():\n",
    "    print(\"=\"*60)\n",
    "    print(\"STARTING K-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    all_accs = []\n",
    "    all_f1s = []\n",
    "\n",
    "    for fold in range(NUM_FOLDS):\n",
    "        acc, f1, cm, hist = train_fold(fold)\n",
    "        all_accs.append(acc)\n",
    "        all_f1s.append(f1)\n",
    "        plot_learning_curves(hist, fold+1)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Mean Accuracy: {np.mean(all_accs):.4f} Â± {np.std(all_accs):.4f}\")\n",
    "    print(f\"Mean F1-score: {np.mean(all_f1s):.4f} Â± {np.std(all_f1s):.4f}\")\n",
    "    print(f\"Individual fold accuracies: {[f'{a:.4f}' for a in all_accs]}\")\n",
    "\n",
    "    if np.mean(all_accs) >= 0.90:\n",
    "        print(f\"\\nðŸŽ‰ SUCCESS! Achieved {np.mean(all_accs)*100:.2f}% average accuracy!\")\n",
    "    else:\n",
    "        print(f\"\\nâš   Current: {np.mean(all_accs)*100:.2f}% - Try adjusting hyperparameters\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
